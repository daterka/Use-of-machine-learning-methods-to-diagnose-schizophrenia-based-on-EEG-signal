{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pywt\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from mne.time_frequency import psd_welch\n",
    "from mne.decoding import Scaler\n",
    "from mne.filter import construct_iir_filter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loading edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "edfs_path = \"..\\dataverse_files\"\n",
    "manifest_path = \"..\\dataverse_files\\MANIFEST.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_patients_data = []\n",
    "\n",
    "edfs_file_names = [f for f in os.listdir(edfs_path) if f.endswith('.edf')]\n",
    "\n",
    "for file_name in edfs_file_names:\n",
    "    path = edfs_path + '\\\\' + file_name \n",
    "    raw_data = mne.io.read_raw_edf(path, preload=True, verbose=False)\n",
    "    raw_patients_data.append(raw_data)\n",
    "\n",
    "edf_file_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG signals filtration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iir_filter_dataset = [\n",
    "    {'order': 2, 'flow': 0.5, 'fhigh': 50},\n",
    "    {'order': 5, 'flow': 0.5, 'fhigh': 50},\n",
    "    {'order': 6, 'flow': 0.5, 'fhigh': 50},\n",
    "    {'order': 2, 'flow': 2, 'fhigh': 45},\n",
    "    {'order': 5, 'flow': 2, 'fhigh': 45},\n",
    "    {'order': 6, 'flow': 2, 'fhigh': 45},\n",
    "    {'order': 5, 'flow': 0.5, 'fhigh': 45},\n",
    "    {'order': 6, 'flow': 0.5, 'fhigh': 45},\n",
    "    {'order': 81, 'fcut': 40, 'fstop': 45},\n",
    "    {'order': 5, 'fcut': 50},\n",
    "    {'order': 6, 'fcut': 50},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 8 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 50.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 20 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 50.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 24 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 50.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 8 (effective, after forward-backward)\n",
      "- Cutoffs at 2.00, 45.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 20 (effective, after forward-backward)\n",
      "- Cutoffs at 2.00, 45.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 24 (effective, after forward-backward)\n",
      "- Cutoffs at 2.00, 45.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 20 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 45.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 24 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 45.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth lowpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 162 (effective, after forward-backward)\n",
      "- Cutoff at 40.00 Hz: -6.02 dB\n",
      "\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth lowpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 10 (effective, after forward-backward)\n",
      "- Cutoff at 50.00 Hz: -6.02 dB\n",
      "\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth lowpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 12 (effective, after forward-backward)\n",
      "- Cutoff at 50.00 Hz: -6.02 dB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bartosz Ziomek\\anaconda3\\envs\\thesis\\lib\\site-packages\\scipy\\signal\\filter_design.py:1631: BadCoefficients: Badly conditioned filter coefficients (numerator): the results may be meaningless\n",
      "  warnings.warn(\"Badly conditioned filter coefficients (numerator): the \"\n"
     ]
    }
   ],
   "source": [
    "iir = []\n",
    "\n",
    "for iir_data in iir_filter_dataset:\n",
    "    btype = 'bandpass'\n",
    "    f_stop = None\n",
    "\n",
    "    if 'flow' in iir_data and 'fhigh' in iir_data:\n",
    "        f_pass = [iir_data['flow'], iir_data['fhigh']]\n",
    "\n",
    "    if 'fcut' in iir_data:\n",
    "        btype = 'lowpass'\n",
    "        f_pass = iir_data['fcut']\n",
    "        if 'fstop' in iir_data:\n",
    "            f_stop = iir_data['fstop']\n",
    "        \n",
    "    iir.append(construct_iir_filter(dict(order=iir_data['order'], ftype='butter', output='sos'), f_pass, f_stop, 250, btype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_patients_data = [raw_patient_data.copy()\n",
    "#                           .filter(l_freq=None, h_freq=None, picks='eeg', method='iir', iir_params=iir[2], n_jobs=-1, verbose=False) \n",
    "#                           for raw_patient_data in raw_patients_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scaling EEG signals with Scaler from MNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mne_std_scaler(edf):\n",
    "#     scaler = Scaler(scalings='mean')\n",
    "#     return [scaler.fit_transform(patient_data.get_data()) for patient_data in edf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mne_robust_scaler(edf):\n",
    "#     scaler = Scaler(scalings='median')\n",
    "#     return [scaler.fit_transform(patient_data.get_data()) for patient_data in edf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mne_std_scaled_patient_data = mne_robust_scaler(filtered_patients_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mne_std_scaled_patient_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtered EEG signals segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(edf):\n",
    "    patient_edf_file_name = edf.filenames[0].split('\\\\')[-1]\n",
    "    isSick = patient_edf_file_name.lower().startswith('s')\n",
    "    return int(isSick == True) # 1 - is sick, 0 is healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(epochs_num_per_patient, labels):\n",
    "    # print('\\nEpochs number per patient: ', epochs_num_per_patient)\n",
    "    \n",
    "    class_0_num = sum(labels) \n",
    "    class_1_num = len(labels)-sum(labels)\n",
    "\n",
    "    # print('\\nnegative: ', class_0_num)\n",
    "    # print('positive: ', class_1_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_patients_data_into_X_y_sets(patients_data, info=True):\n",
    "    epochs_per_patient = []\n",
    "    labels = []\n",
    "    \n",
    "    epochs_num_per_patient = []\n",
    "    for edf in raw_patients_data:\n",
    "        epochs = mne.make_fixed_length_epochs(edf, duration=25, preload=True, verbose=False)\n",
    "        \n",
    "        epochs_per_patient.append(epochs)\n",
    "        epochs_num_per_patient.append(len(epochs))\n",
    "        \n",
    "        label = get_label(edf)\n",
    "        labels.extend([label for epoch in epochs])\n",
    "    \n",
    "    epochs = mne.concatenate_epochs(epochs_per_patient)\n",
    "    \n",
    "    if info:\n",
    "        print_info(epochs_num_per_patient, labels)\n",
    "\n",
    "    return (epochs, labels) # (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_patients_data_into_X_y_sets(patients_data, info=False):\n",
    "    epochs_per_patient = []\n",
    "    labels = []\n",
    "    \n",
    "    for edf in patients_data:\n",
    "        epochs = mne.make_fixed_length_epochs(edf, duration=25, preload=True, verbose=False)\n",
    "        \n",
    "        epochs_per_patient.append(epochs)\n",
    "        \n",
    "        label = get_label(edf)\n",
    "        labels.extend([label for epoch in epochs])\n",
    "    \n",
    "    epochs = mne.concatenate_epochs(epochs_per_patient)\n",
    "    \n",
    "    if info:\n",
    "        print_info(len(epochs), labels)\n",
    "\n",
    "    return (epochs, labels) # (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = transform_patients_data_into_X_y_sets(filtered_patients_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eeg_power_band(epochs):\n",
    "    \"\"\"EEG relative power band feature extraction.\n",
    "\n",
    "    This function takes an ``mne.Epochs`` object and creates EEG features based\n",
    "    on relative power in specific frequency bands that are compatible with\n",
    "    scikit-learn.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epochs : Epochs\n",
    "        The data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy array of shape [n_samples, 5]\n",
    "        Transformed data.\n",
    "    \"\"\"\n",
    "    # specific frequency bands\n",
    "    FREQ_BANDS = {\"delta\": [0.5, 4.5],\n",
    "                  \"theta\": [4.5, 8.5],\n",
    "                  \"alpha\": [8.5, 11.5],\n",
    "                  \"sigma\": [11.5, 15.5],\n",
    "                  \"beta\": [15.5, 30]}\n",
    "\n",
    "    psds, freqs = psd_welch(epochs, picks='eeg', fmin=0.5, fmax=30.)\n",
    "    # Normalize the PSDs\n",
    "    psds /= np.sum(psds, axis=-1, keepdims=True)\n",
    "\n",
    "    X = []\n",
    "    for fmin, fmax in FREQ_BANDS.values():\n",
    "        psds_band = psds[:, :, (freqs >= fmin) & (freqs < fmax)].mean(axis=-1)\n",
    "        X.append(psds_band.reshape(len(psds), -1))\n",
    "\n",
    "    return np.concatenate(X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = eeg_power_band(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_test(features, y, clr):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.33, shuffle=True, random_state=41)\n",
    "\n",
    "    pipe = make_pipeline(\n",
    "        clr\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Test\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    # Assess the results\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### With MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.33, shuffle=True, random_state=41)\n",
    "\n",
    "# pipe = make_pipeline(\n",
    "#     MinMaxScaler(copy=False),\n",
    "#     RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "# )\n",
    "\n",
    "# # Train\n",
    "# pipe.fit(X_train, y_train)\n",
    "\n",
    "# # Test\n",
    "# y_pred = pipe.predict(X_test)\n",
    "\n",
    "# # Assess the results\n",
    "# acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### With MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.33, shuffle=True, random_state=41)\n",
    "\n",
    "# pipe = make_pipeline(\n",
    "#     StandardScaler(copy=False),\n",
    "#     RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "# )\n",
    "\n",
    "# # Train\n",
    "# pipe.fit(X_train, y_train)\n",
    "\n",
    "# # Test\n",
    "# y_pred = pipe.predict(X_test)\n",
    "\n",
    "# # Assess the results\n",
    "# acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### With RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.33, shuffle=True, random_state=41)\n",
    "\n",
    "# pipe = make_pipeline(\n",
    "#     RobustScaler(copy=False),\n",
    "#     RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "# )\n",
    "\n",
    "# # Train\n",
    "# pipe.fit(X_train, y_train)\n",
    "\n",
    "# # Test\n",
    "# y_pred = pipe.predict(X_test)\n",
    "\n",
    "# # Assess the results\n",
    "# acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# print(\"Accuracy score: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validatated Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# scores = cross_val_score(clf, features, y, cv=3)\n",
    "\n",
    "# print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_arr = [KNeighborsClassifier(n_neighbors=2),\n",
    "            RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            SVC(kernel='poly')]\n",
    "\n",
    "res_acc_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bartosz Ziomek\\anaconda3\\envs\\thesis\\lib\\site-packages\\scipy\\signal\\filter_design.py:1631: BadCoefficients: Badly conditioned filter coefficients (numerator): the results may be meaningless\n",
      "  warnings.warn(\"Badly conditioned filter coefficients (numerator): the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bartosz Ziomek\\anaconda3\\envs\\thesis\\lib\\site-packages\\scipy\\signal\\filter_design.py:1631: BadCoefficients: Badly conditioned filter coefficients (numerator): the results may be meaningless\n",
      "  warnings.warn(\"Badly conditioned filter coefficients (numerator): the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bartosz Ziomek\\anaconda3\\envs\\thesis\\lib\\site-packages\\scipy\\signal\\filter_design.py:1631: BadCoefficients: Badly conditioned filter coefficients (numerator): the results may be meaningless\n",
      "  warnings.warn(\"Badly conditioned filter coefficients (numerator): the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n",
      "Not setting metadata\n",
      "1142 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "Effective window size : 1.024 (s)\n"
     ]
    }
   ],
   "source": [
    "for index1, clr in enumerate(clr_arr):\n",
    "    with open(f'result{index1 + 1}.txt', 'w', encoding = 'utf-8') as f:\n",
    "        acc_arr = []\n",
    "\n",
    "        for index, i in enumerate(iir):\n",
    "            filtered_patients_data = [raw_patient_data.copy()\n",
    "                                  .filter(l_freq=None, h_freq=None, picks='eeg', method='iir', iir_params=i, n_jobs=-1, verbose=False) \n",
    "                                  for raw_patient_data in raw_patients_data]\n",
    "\n",
    "            X, y = transform_patients_data_into_X_y_sets(filtered_patients_data)\n",
    "\n",
    "            features = eeg_power_band(X)\n",
    "\n",
    "            acc = class_test(features, y, clr)\n",
    "            acc_arr.append(acc)\n",
    "\n",
    "            filtered_patients_data = []\n",
    "            X = []\n",
    "            y = []\n",
    "            features = []\n",
    "            f.write(f\"{iir_filter_dataset[index]} Accuracy score: {acc}\\n\")\n",
    "\n",
    "        max_acc = max(acc_arr)\n",
    "        f.write(f\"{iir_filter_dataset[acc_arr.index(max_acc)]} -> {max_acc}\\n\")\n",
    "    res_acc_arr.append(acc_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.9372237 , 0.94076039, 0.93633952, 0.93987622, 0.93899204,\n",
       "        0.93810787, 0.93987622, 0.93899204, 0.94429708, 0.94341291,\n",
       "        0.94341291]),\n",
       " 0.9442970822281168)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(np.array(res_acc_arr).T, axis = 1), max(np.average(np.array(res_acc_arr).T, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "iir_filter_dataset = [\n",
    "    {'order': 2, 'flow': 0.5, 'fhigh': 50},\n",
    "    {'order': 5, 'flow': 0.5, 'fhigh': 50},\n",
    "    {'order': 6, 'flow': 0.5, 'fhigh': 50},\n",
    "    {'order': 2, 'flow': 2, 'fhigh': 45},\n",
    "    {'order': 5, 'flow': 2, 'fhigh': 45},\n",
    "    {'order': 6, 'flow': 2, 'fhigh': 45},\n",
    "    {'order': 5, 'flow': 0.5, 'fhigh': 45},\n",
    "    {'order': 6, 'flow': 0.5, 'fhigh': 45},\n",
    "    {'order': 81, 'fcut': 40, 'fstop': 45},\n",
    "    {'order': 5, 'fcut': 50, 'fstop': None},\n",
    "    {'order': 6, 'fcut': 50, 'fstop': None},\n",
    "]\n",
    "\n",
    "conv = np.average(np.array(res_acc_arr).T, axis = 1).tolist();\n",
    "test = [list(iir_filter.values()) for iir_filter in iir_filter_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in enumerate(conv):\n",
    "    test[index].append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test, columns =['Order', 'Flow/Fcut', 'Fhigh/Fstop', 'Avg. acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>Flow/Fcut</th>\n",
       "      <th>Fhigh/Fstop</th>\n",
       "      <th>Avg. acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.936340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.937224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.938108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.938992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.938992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.939876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.939876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.940760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.943413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.943413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.944297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Order  Flow/Fcut  Fhigh/Fstop  Avg. acc\n",
       "2       6        0.5         50.0  0.936340\n",
       "0       2        0.5         50.0  0.937224\n",
       "5       6        2.0         45.0  0.938108\n",
       "4       5        2.0         45.0  0.938992\n",
       "7       6        0.5         45.0  0.938992\n",
       "3       2        2.0         45.0  0.939876\n",
       "6       5        0.5         45.0  0.939876\n",
       "1       5        0.5         50.0  0.940760\n",
       "9       5       50.0          NaN  0.943413\n",
       "10      6       50.0          NaN  0.943413\n",
       "8      81       40.0         45.0  0.944297"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('Avg. acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
