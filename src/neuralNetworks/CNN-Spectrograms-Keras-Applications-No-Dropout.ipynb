{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-Spectrograms-Keras-Applications-With-No-Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "import spectrograms_loader as dataset_loader\n",
    "import model_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = '../../spectrograms_dataset/train/'\n",
    "test_dataset_path = '../../spectrograms_dataset/test/'\n",
    "\n",
    "save_path = '../../../Results/CNN-spectrograms-no-dropout'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (224, 224)\n",
    "data_split_ration = 0.2\n",
    "seed = 1337\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "epochs_n = 100\n",
    "patience_n = 15\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "input_shape = None\n",
    "label_shape = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model build function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining network architecture based on pretreined model\n",
    "def build_model(opt, base_model, flatten = True):\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Create a new 'top' of the model (i.e. fully-connected layers).\n",
    "    # This is 'bootstrapping' a new top_model onto the pretrained layers.\n",
    "    top_model = base_model.output\n",
    "    \n",
    "    if flatten is True:\n",
    "        top_model = Flatten(name=\"flatten\")(top_model)\n",
    "    else:\n",
    "        top_model = GlobalAveragePooling2D(name=\"GlobalAveragePooling2D\")(top_model)\n",
    "            \n",
    "#     top_model = Dropout(0.5)(top_model)\n",
    "\n",
    "    top_model = Dense(512, activation='relu', name=\"fc1\", \n",
    "                      kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "                      bias_regularizer=regularizers.L2(1e-4),\n",
    "                      activity_regularizer=regularizers.L2(1e-5))(top_model)\n",
    "    \n",
    "#     top_model = Dropout(0.4)(top_model)\n",
    "    \n",
    "    output_layer = Dense(1, activation='sigmoid', name=\"prediction\")(top_model)\n",
    "    \n",
    "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
    "    model = Model(inputs=base_model.input, outputs=output_layer, name=base_model.name)\n",
    "\n",
    "    # Compiles the model for training.\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4616 files belonging to 2 classes.\n",
      "Using 3693 files for training.\n",
      "Found 4616 files belonging to 2 classes.\n",
      "Using 923 files for validation.\n",
      "Found 1155 files belonging to 2 classes.\n",
      "\n",
      "classes: ['SZ_negative', 'SZ_positive']\n",
      "\n",
      "input shape: (224, 224, 3)\n",
      "label shape: (1,)\n"
     ]
    }
   ],
   "source": [
    "train_ds, validation_ds, test_ds = dataset_loader.load_datasets(image_shape, train_dataset_path, test_dataset_path, data_split_ration, seed, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([224, 224, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = dataset_loader.input_shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 64\n",
      "learning rate: 0.001\n",
      "epochs: 100\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 512)               12845568  \n",
      "                                                                 \n",
      " prediction (Dense)          (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,560,769\n",
      "Trainable params: 12,846,081\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "58/58 [==============================] - 172s 3s/step - loss: 5.2488 - accuracy: 0.7717 - val_loss: 0.5817 - val_accuracy: 0.8819\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 142s 2s/step - loss: 0.4587 - accuracy: 0.9285 - val_loss: 0.4653 - val_accuracy: 0.9036\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 138s 2s/step - loss: 0.3555 - accuracy: 0.9591 - val_loss: 0.4187 - val_accuracy: 0.9198\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 136s 2s/step - loss: 0.2907 - accuracy: 0.9805 - val_loss: 0.3757 - val_accuracy: 0.9307\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 146s 3s/step - loss: 0.2564 - accuracy: 0.9889 - val_loss: 0.3563 - val_accuracy: 0.9285\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 132s 2s/step - loss: 0.2218 - accuracy: 0.9962 - val_loss: 0.3375 - val_accuracy: 0.9350\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 143s 2s/step - loss: 0.2014 - accuracy: 0.9978 - val_loss: 0.3186 - val_accuracy: 0.9350\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 143s 2s/step - loss: 0.1799 - accuracy: 0.9997 - val_loss: 0.3098 - val_accuracy: 0.9382\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 137s 2s/step - loss: 0.1660 - accuracy: 0.9997 - val_loss: 0.3153 - val_accuracy: 0.9361\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.1542 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "# batch size 64, lr 0.001, epochs 100, patience 15 \n",
    "base_model = tf.keras.applications.VGG16(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "\n",
    "preprocess = tf.keras.applications.vgg16.preprocess_input\n",
    "\n",
    "model_runner.run_pretrained(train_ds, validation_ds, test_ds, input_shape, preprocess, base_model, build_model,\n",
    "    flatten = True, lr = learning_rate, epochs=epochs_n, patience=patience_n, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size 64, lr 0.001, epochs 100, patience 15 \n",
    "base_model = tf.keras.applications.VGG19(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "\n",
    "preprocess = tf.keras.applications.vgg19.preprocess_input\n",
    "\n",
    "model_runner.run_pretrained(train_ds, validation_ds, test_ds, input_shape, preprocess, base_model, build_model,\n",
    "    flatten = True, lr = learning_rate, epochs=epochs_n, patience=patience_n, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size 64, lr 0.001, epochs 100, patience 15 \n",
    "base_model = tf.keras.applications.resnet_v2.ResNet50V2(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "\n",
    "preprocess = tf.keras.applications.resnet_v2.preprocess_input\n",
    "\n",
    "model_runner.run_pretrained(train_ds, validation_ds, test_ds, input_shape, preprocess, base_model, build_model,\n",
    "    flatten = False, lr = learning_rate, epochs=epochs_n, patience=patience_n, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size 64, lr 0.001, epochs 100, patience 15 \n",
    "base_model = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "\n",
    "preprocess = tf.keras.applications.inception_resnet_v2.preprocess_input\n",
    "\n",
    "model_runner.run_pretrained(train_ds, validation_ds, test_ds, input_shape, preprocess, base_model, build_model,\n",
    "    flatten = False, lr = learning_rate, epochs=epochs_n, patience=patience_n, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size 64, lr 0.001, epochs 100, patience 15 \n",
    "base_model = tf.keras.applications.MobileNetV2(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "\n",
    "preprocess = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "model_runner.run_pretrained(train_ds, validation_ds, test_ds, input_shape, preprocess, base_model, build_model,\n",
    "    flatten = False, lr = learning_rate, epochs=epochs_n, patience=patience_n, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size 64, lr 0.001, epochs 100, patience 15 \n",
    "base_model = tf.keras.applications.DenseNet169(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "\n",
    "preprocess = tf.keras.applications.densenet.preprocess_input\n",
    "\n",
    "model_runner.run_pretrained(train_ds, validation_ds, test_ds, input_shape, preprocess, base_model, build_model,\n",
    "    flatten = False, lr = learning_rate, epochs=epochs_n, patience=patience_n, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNetB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size 64, lr 0.001, epochs 100, patience 15 \n",
    "base_model = tf.keras.applications.EfficientNetB2(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "\n",
    "preprocess = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "model_runner.run_pretrained(train_ds, validation_ds, test_ds, input_shape, preprocess, base_model, build_model,\n",
    "    flatten = False, lr = learning_rate, epochs=epochs_n, patience=patience_n, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size 64, lr 0.001, epochs 100, patience 15 \n",
    "base_model = tf.keras.applications.Xception(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "\n",
    "preprocess = tf.keras.applications.xception.preprocess_input\n",
    "\n",
    "model_runner.run_pretrained(train_ds, validation_ds, test_ds, input_shape, preprocess, base_model, build_model,\n",
    "    flatten = False, lr = learning_rate, epochs=epochs_n, patience=patience_n, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size 64, lr 0.001, epochs 100, patience 15 \n",
    "base_model = tf.keras.applications.nasnet.NASNetMobile(include_top=False,\n",
    "                     weights='imagenet', \n",
    "                     input_shape=input_shape)\n",
    "\n",
    "preprocess = tf.keras.applications.nasnet.preprocess_input\n",
    "\n",
    "model_runner.run_pretrained(train_ds, validation_ds, test_ds, input_shape, preprocess, base_model, build_model,\n",
    "    flatten = False, lr = learning_rate, epochs=epochs_n, patience=patience_n, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
