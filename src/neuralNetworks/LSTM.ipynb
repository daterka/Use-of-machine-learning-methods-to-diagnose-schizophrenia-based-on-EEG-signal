{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "013adb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras import regularizers\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sn\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import mne\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Input, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf85520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37858209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69de941a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d5d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5ff259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1398a097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ae4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31d598ef",
   "metadata": {},
   "source": [
    "### Loading edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eb29333",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"..\\dataverse_files\\h01.edf\"\n",
    "edfs_path = \"..\\dataverse_files\"\n",
    "manifest_path = \"..\\dataverse_files\\MANIFEST.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0046338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patients_data(edfs_path):\n",
    "    raw_patients_data = []\n",
    "    \n",
    "    edfs_file_names = [f for f in os.listdir(edfs_path) if f.endswith('.edf')]\n",
    "    \n",
    "    for file_name in edfs_file_names:\n",
    "        path = edfs_path + '\\\\' + file_name \n",
    "        raw_data = mne.io.read_raw_edf(path, preload=True, verbose=False)\n",
    "        raw_patients_data.append(raw_data)\n",
    "\n",
    "    return raw_patients_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f220cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_patients_data = load_patients_data(edfs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec70c1",
   "metadata": {},
   "source": [
    "### Filtered EEG signals segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8e14626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(edf):\n",
    "    patient_edf_file_name = edf.filenames[0].split('\\\\')[-1]\n",
    "    isSick = patient_edf_file_name.lower().startswith('s')\n",
    "    return int(isSick == True) # 1 - is sick, 0 is healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "141466d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max_duration_for_classes(print_durations=False):\n",
    "    min_SZ_negative_duration = float(\"inf\") # healthy\n",
    "    min_SZ_positive_duration = float(\"inf\") # sick\n",
    "\n",
    "    max_SZ_negative_duration = 0 # healthy\n",
    "    max_SZ_positive_duration = 0 # sick\n",
    "\n",
    "    for edf in raw_patients_data:\n",
    "        duration = edf.times[-1]\n",
    "\n",
    "        if(get_label(edf) == 0):\n",
    "            min_SZ_negative_duration = duration if duration < min_SZ_negative_duration else min_SZ_negative_duration\n",
    "            max_SZ_negative_duration = duration if duration > max_SZ_negative_duration else max_SZ_negative_duration\n",
    "        else:\n",
    "            min_SZ_positive_duration = duration if duration < min_SZ_positive_duration else min_SZ_positive_duration\n",
    "            max_SZ_positive_duration = duration if duration > max_SZ_positive_duration else max_SZ_positive_duration\n",
    "\n",
    "\n",
    "    print('SZ_negative: min =', min_SZ_negative_duration, ', max =', max_SZ_negative_duration)\n",
    "    print('SZ_positive: min =', min_SZ_positive_duration, ', max =', max_SZ_positive_duration)\n",
    "    \n",
    "    return min_SZ_negative_duration, min_SZ_positive_duration, max_SZ_negative_duration, max_SZ_positive_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "505e8b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_raw_data_to_equalize_duration_per_class():\n",
    "    print(\"Duration per class before cropping: \")\n",
    "    min_dur_neg, min_dur_pos, *_ = get_min_max_duration_for_classes(True)\n",
    "    \n",
    "    for edf in raw_patients_data:\n",
    "        duration = edf.times[-1]\n",
    "\n",
    "        if(get_label(edf) == 0):\n",
    "            if(duration > min_dur_neg):\n",
    "                edf.crop(tmin=0, tmax=min_dur_neg, include_tmax=True)\n",
    "        else:\n",
    "            if(duration > min_dur_pos):\n",
    "                edf.crop(tmin=0, tmax=min_dur_pos, include_tmax=True)\n",
    "                \n",
    "    print(\"\\nDuration per class after cropping: \")\n",
    "\n",
    "    get_min_max_duration_for_classes(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b81024bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(epochs_num_per_patient, labels):\n",
    "    print('\\nEpochs number per patient: ', epochs_num_per_patient)\n",
    "    \n",
    "    class_SZ_positive = sum(labels) \n",
    "    class_SZ_negative= len(labels)-sum(labels)\n",
    "\n",
    "    print('\\nnegative: ', class_SZ_positive)\n",
    "    print('positive: ', class_SZ_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4068381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_patients_data_into_X_y_sets(patients_data, segment_duration=5.0, info=True):\n",
    "    epochs_per_patient = []\n",
    "    labels = []\n",
    "    \n",
    "    epochs_num_per_patient = []\n",
    "    for edf in raw_patients_data:\n",
    "        epochs = mne.make_fixed_length_epochs(edf, duration=segment_duration, preload=True, verbose=False)\n",
    "        epochs_per_patient.append(epochs)\n",
    "        epochs_num_per_patient.append(len(epochs))\n",
    "        \n",
    "        label = get_label(edf)\n",
    "        labels.extend([label for epoch in epochs])\n",
    "    \n",
    "    epochs = mne.concatenate_epochs(epochs_per_patient)\n",
    "\n",
    "    if info:\n",
    "        print_info(epochs_num_per_patient, labels)\n",
    "        \n",
    "    del epochs_num_per_patient\n",
    "    gc.collect()\n",
    "    \n",
    "    return (epochs, np.array(labels)) # (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a29ba119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# crop_raw_data_to_equalize_duration_per_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf262ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "5771 matching events found\n",
      "No baseline correction applied\n",
      "0 bad epochs dropped\n",
      "\n",
      "Epochs number per patient:  [185, 182, 182, 185, 189, 186, 182, 182, 181, 223, 183, 180, 193, 173, 169, 229, 192, 241, 178, 148, 269, 182, 237, 170, 272, 217, 227, 434]\n",
      "\n",
      "negative:  3165\n",
      "positive:  2606\n"
     ]
    }
   ],
   "source": [
    "X, y = transform_patients_data_into_X_y_sets(patients_data=raw_patients_data, segment_duration=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0be89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a090f18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del raw_patients_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee78e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5705716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5771\n",
      "5771\n",
      "(1, 19, 1250)\n"
     ]
    }
   ],
   "source": [
    "print(len(y))\n",
    "print(len(X))\n",
    "print(X[0].get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1dccd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>condition</th>\n",
       "      <th>epoch</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>F8</th>\n",
       "      <th>T4</th>\n",
       "      <th>T6</th>\n",
       "      <th>O2</th>\n",
       "      <th>Fp1</th>\n",
       "      <th>F7</th>\n",
       "      <th>...</th>\n",
       "      <th>O1</th>\n",
       "      <th>F4</th>\n",
       "      <th>C4</th>\n",
       "      <th>P4</th>\n",
       "      <th>F3</th>\n",
       "      <th>C3</th>\n",
       "      <th>P3</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "      <th>Pz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461215</td>\n",
       "      <td>0.461215</td>\n",
       "      <td>0.308310</td>\n",
       "      <td>0.30831</td>\n",
       "      <td>0.155405</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.150405</td>\n",
       "      <td>-0.30331</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.303310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461215</td>\n",
       "      <td>0.461215</td>\n",
       "      <td>0.461215</td>\n",
       "      <td>0.30831</td>\n",
       "      <td>0.155405</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.30331</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.155405</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.150405</td>\n",
       "      <td>-0.30331</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.150405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time condition  epoch       Fp2        F8        T4       T6        O2  \\\n",
       "0     0         1      0  0.002500  0.002500  0.002500  0.00250  0.002500   \n",
       "1     4         1      0  0.002500  0.002500  0.002500  0.00250  0.002500   \n",
       "2     8         1      0  0.002500  0.002500  0.002500  0.00250  0.002500   \n",
       "3    12         1      0  0.461215  0.461215  0.308310  0.30831  0.155405   \n",
       "4    16         1      0  0.461215  0.461215  0.461215  0.30831  0.155405   \n",
       "\n",
       "      Fp1      F7  ...       O1      F4        C4      P4      F3        C3  \\\n",
       "0  0.0025  0.0025  ...  0.00250  0.0025  0.002500  0.0025  0.0025  0.002500   \n",
       "1  0.0025  0.0025  ...  0.00250  0.0025  0.002500  0.0025  0.0025  0.002500   \n",
       "2  0.0025  0.0025  ...  0.00250  0.0025  0.002500  0.0025  0.0025  0.002500   \n",
       "3  0.0025  0.0025  ...  0.00250  0.0025  0.002500  0.0025  0.0025 -0.150405   \n",
       "4  0.0025  0.0025  ... -0.30331  0.0025  0.155405  0.0025  0.0025 -0.150405   \n",
       "\n",
       "        P3      Fz      Cz        Pz  \n",
       "0  0.00250  0.0025  0.0025  0.002500  \n",
       "1  0.00250  0.0025  0.0025  0.002500  \n",
       "2  0.00250  0.0025  0.0025  0.002500  \n",
       "3 -0.30331  0.0025  0.0025 -0.303310  \n",
       "4 -0.30331  0.0025  0.0025 -0.150405  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.to_data_frame().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8633457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>condition</th>\n",
       "      <th>epoch</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>F8</th>\n",
       "      <th>T4</th>\n",
       "      <th>T6</th>\n",
       "      <th>O2</th>\n",
       "      <th>Fp1</th>\n",
       "      <th>F7</th>\n",
       "      <th>...</th>\n",
       "      <th>O1</th>\n",
       "      <th>F4</th>\n",
       "      <th>C4</th>\n",
       "      <th>P4</th>\n",
       "      <th>F3</th>\n",
       "      <th>C3</th>\n",
       "      <th>P3</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "      <th>Pz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461215</td>\n",
       "      <td>0.461215</td>\n",
       "      <td>0.308310</td>\n",
       "      <td>0.30831</td>\n",
       "      <td>0.155405</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00250</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.150405</td>\n",
       "      <td>-0.30331</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.303310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.461215</td>\n",
       "      <td>0.461215</td>\n",
       "      <td>0.461215</td>\n",
       "      <td>0.30831</td>\n",
       "      <td>0.155405</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.30331</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.155405</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.150405</td>\n",
       "      <td>-0.30331</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>-0.150405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time condition  epoch       Fp2        F8        T4       T6        O2  \\\n",
       "0     0         1      0  0.002500  0.002500  0.002500  0.00250  0.002500   \n",
       "1     4         1      0  0.002500  0.002500  0.002500  0.00250  0.002500   \n",
       "2     8         1      0  0.002500  0.002500  0.002500  0.00250  0.002500   \n",
       "3    12         1      0  0.461215  0.461215  0.308310  0.30831  0.155405   \n",
       "4    16         1      0  0.461215  0.461215  0.461215  0.30831  0.155405   \n",
       "\n",
       "      Fp1      F7  ...       O1      F4        C4      P4      F3        C3  \\\n",
       "0  0.0025  0.0025  ...  0.00250  0.0025  0.002500  0.0025  0.0025  0.002500   \n",
       "1  0.0025  0.0025  ...  0.00250  0.0025  0.002500  0.0025  0.0025  0.002500   \n",
       "2  0.0025  0.0025  ...  0.00250  0.0025  0.002500  0.0025  0.0025  0.002500   \n",
       "3  0.0025  0.0025  ...  0.00250  0.0025  0.002500  0.0025  0.0025 -0.150405   \n",
       "4  0.0025  0.0025  ... -0.30331  0.0025  0.155405  0.0025  0.0025 -0.150405   \n",
       "\n",
       "        P3      Fz      Cz        Pz  \n",
       "0  0.00250  0.0025  0.0025  0.002500  \n",
       "1  0.00250  0.0025  0.0025  0.002500  \n",
       "2  0.00250  0.0025  0.0025  0.002500  \n",
       "3 -0.30331  0.0025  0.0025 -0.303310  \n",
       "4 -0.30331  0.0025  0.0025 -0.150405  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].to_data_frame().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68db9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Data preparation\n",
    "\n",
    "# np.set_printoptions(precision=50)\n",
    "\n",
    "# x_data = X.get_data()\n",
    "# print('x_data shape:', x_data.shape)\n",
    "\n",
    "# column_names = X[0].to_data_frame().columns\n",
    "# column_names = column_names[-19:]\n",
    "# print('column_names:', column_names)\n",
    "\n",
    "# epoch_num, channel_num, epoch_len = x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "761ffb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ee0488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01ae77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75c76b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# # scaled = scaler.fit_transform(data_2['X_train'])\n",
    "# # scaled\n",
    "\n",
    "# scalers = {}\n",
    "# for i in range(x_data.shape[1]):\n",
    "#     scalers[i] = MinMaxScaler()\n",
    "#     x_data[:, i, :] = scalers[i].fit_transform(x_data[:, i, :]) \n",
    "\n",
    "# # for i in range(X_test.shape[1]):\n",
    "# #     X_test[:, i, :] = scalers[i].transform(X_test[:, i, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6d0b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c05dc4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # x_data = x_data.swapaxes(1, 2)\n",
    "# x_data_shape = x_data.shape\n",
    "# print(x_data_shape)\n",
    "# x_data = x_data.reshape(x_data_shape[0], x_data_shape[2], x_data_shape[1])\n",
    "# x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "328764ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7810dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2de4364f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5771"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db610d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7165000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1433*5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "674429b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 19, 1250)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_shape = X[0].get_data().shape\n",
    "X_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d35dc492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5771, 1250, 19)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_shape = (len(X), X_shape[2], X_shape[1])\n",
    "X_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad5be828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5771, 1250, 19)\n"
     ]
    }
   ],
   "source": [
    "X_data = np.zeros(shape=X_shape)\n",
    "print(X_data.shape)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    df = X[i].to_data_frame().drop(['time', 'condition', 'epoch'], axis=1)\n",
    "#     np.concatenate(x_data, df.to_numpy())\n",
    "    epoch_data = df.to_numpy()\n",
    "    X_data[i] = epoch_data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff47dae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.50000000e-03,  2.50000000e-03,  2.50000000e-03, ...,\n",
       "          2.50000000e-03,  2.50000000e-03,  2.50000000e-03],\n",
       "        [ 2.50000000e-03,  2.50000000e-03,  2.50000000e-03, ...,\n",
       "          2.50000000e-03,  2.50000000e-03,  2.50000000e-03],\n",
       "        [ 2.50000000e-03,  2.50000000e-03,  2.50000000e-03, ...,\n",
       "          2.50000000e-03,  2.50000000e-03,  2.50000000e-03],\n",
       "        ...,\n",
       "        [-1.98526673e+00, -6.11370533e+00, -5.65498993e+00, ...,\n",
       "         -3.82012833e+00, -2.13817186e+00,  2.90769753e+00],\n",
       "        [-2.29107700e+00, -2.74979240e+00, -4.27884373e+00, ...,\n",
       "         -1.67945647e+00, -2.29107700e+00,  3.08310266e-01],\n",
       "        [-1.67945647e+00,  3.08310266e-01, -1.98526673e+00, ...,\n",
       "          2.50000000e-03, -1.83236160e+00, -1.22074107e+00]],\n",
       "\n",
       "       [[ 2.50000000e-03,  3.21350780e+00,  2.50000000e-03, ...,\n",
       "          1.07283593e+00, -2.44398213e+00, -4.27884373e+00],\n",
       "        [-2.44398213e+00,  3.08310266e-01, -2.44398213e+00, ...,\n",
       "          7.67025666e-01, -3.97303346e+00, -8.25437719e+00],\n",
       "        [-2.59688726e+00, -9.14930799e-01, -6.11370533e+00, ...,\n",
       "         -4.56215400e-01, -5.34917966e+00, -1.37589620e+01],\n",
       "        ...,\n",
       "        [ 1.31523415e+01,  3.67222320e+00,  3.82512833e+00, ...,\n",
       "         -1.50405133e-01, -4.56215400e-01,  1.05529542e+01],\n",
       "        [ 9.78842853e+00,  7.67025666e-01,  3.08310266e-01, ...,\n",
       "         -7.62025666e-01, -2.13817186e+00,  9.02390286e+00],\n",
       "        [ 7.18904126e+00, -3.82012833e+00, -1.52655133e+00, ...,\n",
       "         -1.98526673e+00, -1.52655133e+00,  7.18904126e+00]],\n",
       "\n",
       "       [[ 1.07058593e+01, -3.66722320e+00, -1.52655133e+00, ...,\n",
       "          4.61215400e-01,  2.50000000e-03,  6.73032586e+00],\n",
       "        [ 8.71809259e+00, -5.50208480e+00, -3.97303346e+00, ...,\n",
       "         -1.83236160e+00, -9.14930799e-01,  1.22574107e+00],\n",
       "        [ 9.32971313e+00, -4.89046426e+00, -2.44398213e+00, ...,\n",
       "         -1.06783593e+00, -1.37364620e+00, -1.37364620e+00],\n",
       "        ...,\n",
       "        [ 8.25937719e+00,  1.07283593e+00, -2.29107700e+00, ...,\n",
       "         -1.06783593e+00, -9.14930799e-01,  9.94133366e+00],\n",
       "        [ 1.31523415e+01,  6.57742073e+00,  2.60188726e+00, ...,\n",
       "          2.90769753e+00,  3.08310266e-01,  9.17680799e+00],\n",
       "        [ 1.02471439e+01,  5.81289506e+00,  3.21350780e+00, ...,\n",
       "          1.83736160e+00, -7.62025666e-01,  6.42451559e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-8.95954558e-01,  6.61746373e+00,  1.09108456e+01, ...,\n",
       "         -5.01044552e+00,  1.26997547e+01,  9.30082740e+00],\n",
       "        [ 1.57409002e+01,  2.52221185e+01,  1.52042275e+01, ...,\n",
       "          1.53831184e+01,  1.64564639e+01,  1.34153184e+01],\n",
       "        [ 1.78875912e+01,  2.79054822e+01, -2.14819094e+00, ...,\n",
       "          1.96765003e+01, -7.17063646e-01, -3.22153641e+00],\n",
       "        ...,\n",
       "        [-8.95954558e-01, -1.30605365e+01,  3.93410005e+00, ...,\n",
       "          1.44886638e+01,  7.15413646e+00,  7.86970011e+00],\n",
       "        [-1.66383548e+01, -3.36329914e+01, -1.21660820e+01, ...,\n",
       "         -3.57931823e+00, -8.58826376e+00, -8.58826376e+00],\n",
       "        [-3.30963186e+01, -5.36687735e+01, -6.44157282e+00, ...,\n",
       "         -2.12895185e+01, -2.68486367e+00, -2.86375459e+00]],\n",
       "\n",
       "       [[-2.73718095e+01, -4.93753916e+01,  1.34153184e+01, ...,\n",
       "         -1.68172457e+01,  1.77087002e+01,  1.77087002e+01],\n",
       "        [-5.36822735e+00, -2.88029368e+01,  1.80664821e+01, ...,\n",
       "          3.75520914e+00,  2.27176458e+01,  2.28965367e+01],\n",
       "        [ 1.96630003e+00, -2.12895185e+01,  3.03964550e+00, ...,\n",
       "          1.16264093e+01,  6.97524555e+00,  7.33302738e+00],\n",
       "        ...,\n",
       "        [ 1.80664821e+01,  1.91398275e+01,  7.51191829e+00, ...,\n",
       "          1.75298093e+01,  5.72300917e+00,  5.35172735e-01],\n",
       "        [ 6.43857282e+00,  4.29188188e+00, -9.12493649e+00, ...,\n",
       "          3.03964550e+00, -9.84050014e+00, -1.61016820e+01],\n",
       "        [-1.03771729e+01, -1.48494457e+01, -6.97824555e+00, ...,\n",
       "         -1.41338820e+01, -6.26268191e+00, -1.19871911e+01]],\n",
       "\n",
       "       [[-7.87270011e+00, -1.18083002e+01,  1.12686274e+01, ...,\n",
       "         -9.12493649e+00,  1.19841911e+01,  6.79635464e+00],\n",
       "        [ 1.07319547e+01,  7.86970011e+00,  1.87820457e+01, ...,\n",
       "          1.19841911e+01,  1.78875912e+01,  1.26997547e+01],\n",
       "        [ 1.82453730e+01,  1.64564639e+01,  5.90190008e+00, ...,\n",
       "          2.07498457e+01,  2.68186367e+00, -2.68486367e+00],\n",
       "        ...,\n",
       "        [-1.50000000e-03, -1.50000000e-03, -1.50000000e-03, ...,\n",
       "         -1.50000000e-03, -1.50000000e-03, -1.50000000e-03],\n",
       "        [-1.50000000e-03, -1.50000000e-03, -1.50000000e-03, ...,\n",
       "         -1.50000000e-03, -1.50000000e-03, -1.50000000e-03],\n",
       "        [-1.50000000e-03, -1.50000000e-03, -1.50000000e-03, ...,\n",
       "         -1.50000000e-03, -1.50000000e-03, -1.50000000e-03]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c6828a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = X.to_data_frame().drop(['time', 'condition', 'epoch'], axis=1)\n",
    "\n",
    "# X_data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a21b62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5771, 1250, 19)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 2.50000000e-03,  2.50000000e-03,  2.50000000e-03, ...,\n",
       "          2.50000000e-03,  2.50000000e-03,  2.50000000e-03],\n",
       "        [ 2.50000000e-03,  2.50000000e-03,  2.50000000e-03, ...,\n",
       "          2.50000000e-03,  2.50000000e-03,  2.50000000e-03],\n",
       "        [ 2.50000000e-03,  2.50000000e-03,  2.50000000e-03, ...,\n",
       "          2.50000000e-03,  2.50000000e-03,  2.50000000e-03],\n",
       "        ...,\n",
       "        [-1.98526673e+00, -6.11370533e+00, -5.65498993e+00, ...,\n",
       "         -3.82012833e+00, -2.13817186e+00,  2.90769753e+00],\n",
       "        [-2.29107700e+00, -2.74979240e+00, -4.27884373e+00, ...,\n",
       "         -1.67945647e+00, -2.29107700e+00,  3.08310266e-01],\n",
       "        [-1.67945647e+00,  3.08310266e-01, -1.98526673e+00, ...,\n",
       "          2.50000000e-03, -1.83236160e+00, -1.22074107e+00]],\n",
       "\n",
       "       [[ 2.50000000e-03,  3.21350780e+00,  2.50000000e-03, ...,\n",
       "          1.07283593e+00, -2.44398213e+00, -4.27884373e+00],\n",
       "        [-2.44398213e+00,  3.08310266e-01, -2.44398213e+00, ...,\n",
       "          7.67025666e-01, -3.97303346e+00, -8.25437719e+00],\n",
       "        [-2.59688726e+00, -9.14930799e-01, -6.11370533e+00, ...,\n",
       "         -4.56215400e-01, -5.34917966e+00, -1.37589620e+01],\n",
       "        ...,\n",
       "        [ 1.31523415e+01,  3.67222320e+00,  3.82512833e+00, ...,\n",
       "         -1.50405133e-01, -4.56215400e-01,  1.05529542e+01],\n",
       "        [ 9.78842853e+00,  7.67025666e-01,  3.08310266e-01, ...,\n",
       "         -7.62025666e-01, -2.13817186e+00,  9.02390286e+00],\n",
       "        [ 7.18904126e+00, -3.82012833e+00, -1.52655133e+00, ...,\n",
       "         -1.98526673e+00, -1.52655133e+00,  7.18904126e+00]],\n",
       "\n",
       "       [[ 1.07058593e+01, -3.66722320e+00, -1.52655133e+00, ...,\n",
       "          4.61215400e-01,  2.50000000e-03,  6.73032586e+00],\n",
       "        [ 8.71809259e+00, -5.50208480e+00, -3.97303346e+00, ...,\n",
       "         -1.83236160e+00, -9.14930799e-01,  1.22574107e+00],\n",
       "        [ 9.32971313e+00, -4.89046426e+00, -2.44398213e+00, ...,\n",
       "         -1.06783593e+00, -1.37364620e+00, -1.37364620e+00],\n",
       "        ...,\n",
       "        [ 8.25937719e+00,  1.07283593e+00, -2.29107700e+00, ...,\n",
       "         -1.06783593e+00, -9.14930799e-01,  9.94133366e+00],\n",
       "        [ 1.31523415e+01,  6.57742073e+00,  2.60188726e+00, ...,\n",
       "          2.90769753e+00,  3.08310266e-01,  9.17680799e+00],\n",
       "        [ 1.02471439e+01,  5.81289506e+00,  3.21350780e+00, ...,\n",
       "          1.83736160e+00, -7.62025666e-01,  6.42451559e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-8.95954558e-01,  6.61746373e+00,  1.09108456e+01, ...,\n",
       "         -5.01044552e+00,  1.26997547e+01,  9.30082740e+00],\n",
       "        [ 1.57409002e+01,  2.52221185e+01,  1.52042275e+01, ...,\n",
       "          1.53831184e+01,  1.64564639e+01,  1.34153184e+01],\n",
       "        [ 1.78875912e+01,  2.79054822e+01, -2.14819094e+00, ...,\n",
       "          1.96765003e+01, -7.17063646e-01, -3.22153641e+00],\n",
       "        ...,\n",
       "        [-8.95954558e-01, -1.30605365e+01,  3.93410005e+00, ...,\n",
       "          1.44886638e+01,  7.15413646e+00,  7.86970011e+00],\n",
       "        [-1.66383548e+01, -3.36329914e+01, -1.21660820e+01, ...,\n",
       "         -3.57931823e+00, -8.58826376e+00, -8.58826376e+00],\n",
       "        [-3.30963186e+01, -5.36687735e+01, -6.44157282e+00, ...,\n",
       "         -2.12895185e+01, -2.68486367e+00, -2.86375459e+00]],\n",
       "\n",
       "       [[-2.73718095e+01, -4.93753916e+01,  1.34153184e+01, ...,\n",
       "         -1.68172457e+01,  1.77087002e+01,  1.77087002e+01],\n",
       "        [-5.36822735e+00, -2.88029368e+01,  1.80664821e+01, ...,\n",
       "          3.75520914e+00,  2.27176458e+01,  2.28965367e+01],\n",
       "        [ 1.96630003e+00, -2.12895185e+01,  3.03964550e+00, ...,\n",
       "          1.16264093e+01,  6.97524555e+00,  7.33302738e+00],\n",
       "        ...,\n",
       "        [ 1.80664821e+01,  1.91398275e+01,  7.51191829e+00, ...,\n",
       "          1.75298093e+01,  5.72300917e+00,  5.35172735e-01],\n",
       "        [ 6.43857282e+00,  4.29188188e+00, -9.12493649e+00, ...,\n",
       "          3.03964550e+00, -9.84050014e+00, -1.61016820e+01],\n",
       "        [-1.03771729e+01, -1.48494457e+01, -6.97824555e+00, ...,\n",
       "         -1.41338820e+01, -6.26268191e+00, -1.19871911e+01]],\n",
       "\n",
       "       [[-7.87270011e+00, -1.18083002e+01,  1.12686274e+01, ...,\n",
       "         -9.12493649e+00,  1.19841911e+01,  6.79635464e+00],\n",
       "        [ 1.07319547e+01,  7.86970011e+00,  1.87820457e+01, ...,\n",
       "          1.19841911e+01,  1.78875912e+01,  1.26997547e+01],\n",
       "        [ 1.82453730e+01,  1.64564639e+01,  5.90190008e+00, ...,\n",
       "          2.07498457e+01,  2.68186367e+00, -2.68486367e+00],\n",
       "        ...,\n",
       "        [-1.50000000e-03, -1.50000000e-03, -1.50000000e-03, ...,\n",
       "         -1.50000000e-03, -1.50000000e-03, -1.50000000e-03],\n",
       "        [-1.50000000e-03, -1.50000000e-03, -1.50000000e-03, ...,\n",
       "         -1.50000000e-03, -1.50000000e-03, -1.50000000e-03],\n",
       "        [-1.50000000e-03, -1.50000000e-03, -1.50000000e-03, ...,\n",
       "         -1.50000000e-03, -1.50000000e-03, -1.50000000e-03]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_data.shape)\n",
    "\n",
    "X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "163aaa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data = X_data.reshape(-1, 5000, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06916481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efc85b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = X[0].to_data_frame()\n",
    "# df = df.drop(['time', 'condition', 'epoch'], axis=1)\n",
    "\n",
    "# X_data = df.to_numpy()\n",
    "\n",
    "# X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1d16bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 19)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (X_data.shape[1], X_data.shape[2])\n",
    "# input_shape = (5000, 19)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59f17c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(x_data, y, test_size=0.2, shuffle=True, random_state=1337)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y, test_size=0.2, shuffle=True, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea55e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# # scaled = scaler.fit_transform(data_2['X_train'])\n",
    "# # scaled\n",
    "\n",
    "# scalers = {}\n",
    "# for i in range(X_train.shape[1]):\n",
    "#     scalers[i] = MinMaxScaler()\n",
    "#     X_train[:, i, :] = scalers[i].fit_transform(X_train[:, i, :]) \n",
    "\n",
    "# for i in range(X_test.shape[1]):\n",
    "#     X_test[:, i, :] = scalers[i].transform(X_test[:, i, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c5571b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "070a50ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "# X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2, shuffle=True, random_state=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691ec63e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce6232d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a213661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reshape(-1,1)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66412fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4616, 1250, 19)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfba781e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1155, 1250, 19)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f0c6504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "888a7ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 3.83672570e+00  8.95035997e+00 -1.27690857e+00 ...  1.70604476e+00\n",
      "    1.84809015e+00 -2.98145332e+00]\n",
      "  [ 2.84240793e+00  7.10376981e+00 -3.26554411e+00 ...  1.70604476e+00\n",
      "    3.26854411e+00 -1.70304476e+00]\n",
      "  [ 9.95817774e-01  5.68331585e+00 -5.68031585e+00 ...  8.53772378e-01\n",
      "    2.84240793e+00 -2.41327174e+00]\n",
      "  ...\n",
      "  [-1.33507673e+01 -1.30666765e+01 -3.26554411e+00 ... -1.57655390e+01\n",
      "   -6.67463363e+00  3.83672570e+00]\n",
      "  [-7.10076981e+00 -8.80531457e+00 -2.55531713e+00 ... -1.19303133e+01\n",
      "   -4.82804347e+00  4.68899808e+00]\n",
      "  [-5.39622506e+00 -7.66895140e+00 -3.54963491e+00 ... -1.02257685e+01\n",
      "   -4.68599808e+00  2.70036253e+00]]\n",
      "\n",
      " [[ 1.11645747e+01  9.02390286e+00  2.75479240e+00 ...  2.60188726e+00\n",
      "   -6.09120533e-01 -1.37364620e+00]\n",
      "  [ 9.78842853e+00  7.95356693e+00  2.14317186e+00 ...  2.44898213e+00\n",
      "   -1.37364620e+00 -2.29107700e+00]\n",
      "  [ 1.17761953e+01  7.64775666e+00  1.37864620e+00 ...  3.21350780e+00\n",
      "   -4.56215400e-01 -2.44398213e+00]\n",
      "  ...\n",
      "  [ 1.77394955e+01  1.19291004e+01  1.22574107e+00 ...  8.87099773e+00\n",
      "    3.06060266e+00 -3.97303346e+00]\n",
      "  [ 1.83511160e+01  1.11645747e+01  1.22574107e+00 ...  7.80066179e+00\n",
      "    2.75479240e+00 -1.83236160e+00]\n",
      "  [ 1.63633493e+01  1.11645747e+01  2.29607700e+00 ...  6.73032586e+00\n",
      "    3.97803346e+00 -9.14930799e-01]]\n",
      "\n",
      " [[ 3.42532498e+01  1.55405133e-01  3.82512833e+00 ... -1.80403057e+01\n",
      "   -1.33002466e+01 -9.17180799e+00]\n",
      "  [ 2.99719061e+01 -7.79566179e+00  2.14317186e+00 ... -2.35448905e+01\n",
      "   -1.77344955e+01 -1.16182901e+01]\n",
      "  [ 2.89015702e+01 -6.87823099e+00  1.83736160e+00 ... -2.04867879e+01\n",
      "   -1.71228749e+01 -1.13124799e+01]\n",
      "  ...\n",
      "  [ 1.53155133e+00  3.67222320e+00  3.51931806e+00 ... -4.73755913e+00\n",
      "   -6.72532586e+00 -6.41951559e+00]\n",
      "  [-9.14930799e-01  4.61215400e-01  5.81289506e+00 ... -9.47761826e+00\n",
      "   -9.17180799e+00 -6.26661046e+00]\n",
      "  [-6.57242073e+00 -5.50208480e+00  3.97803346e+00 ... -1.40647723e+01\n",
      "   -1.20770055e+01 -6.26661046e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.55405133e-01 -7.62025666e-01  6.14120533e-01 ...  4.61215400e-01\n",
      "   -2.29107700e+00 -3.05560266e+00]\n",
      "  [ 7.49485153e+00  5.20127453e+00  2.75479240e+00 ...  3.36641293e+00\n",
      "   -1.50405133e-01  3.08310266e-01]\n",
      "  [ 6.11870533e+00  1.83736160e+00  2.90769753e+00 ...  1.83736160e+00\n",
      "    1.55405133e-01  2.50000000e-03]\n",
      "  ...\n",
      "  [ 9.02390286e+00  6.57742073e+00  4.13093860e+00 ...  6.73032586e+00\n",
      "    1.83736160e+00 -3.05560266e+00]\n",
      "  [ 6.42451559e+00  8.10647206e+00  3.36641293e+00 ...  3.67222320e+00\n",
      "   -1.06783593e+00 -5.19627453e+00]\n",
      "  [ 6.57742073e+00  1.46813928e+01  1.14703850e+01 ...  3.06060266e+00\n",
      "   -1.67945647e+00 -5.65498993e+00]]\n",
      "\n",
      " [[ 1.36110569e+01  7.49485153e+00  1.53155133e+00 ...  1.36110569e+01\n",
      "    1.13174799e+01 -7.18404126e+00]\n",
      "  [ 4.89546426e+00  1.22574107e+00  4.61215400e-01 ...  8.56518746e+00\n",
      "    9.02390286e+00 -6.57242073e+00]\n",
      "  [-3.05560266e+00 -4.89046426e+00 -1.83236160e+00 ...  3.36641293e+00\n",
      "    6.11870533e+00 -4.27884373e+00]\n",
      "  ...\n",
      "  [-1.11595747e+01 -1.11595747e+01 -1.26886261e+01 ... -4.89046426e+00\n",
      "    3.08310266e-01  2.50000000e-03]\n",
      "  [-4.58465400e+00 -5.50208480e+00 -8.86599773e+00 ... -3.03310266e-01\n",
      "    3.97803346e+00 -1.22074107e+00]\n",
      "  [ 4.61215400e-01 -4.56215400e-01 -5.04336940e+00 ...  4.58965400e+00\n",
      "    7.34194639e+00 -1.83236160e+00]]\n",
      "\n",
      " [[ 5.35172735e-01  1.34153184e+01  1.64564639e+01 ...  6.25968191e+00\n",
      "    6.79635464e+00  2.50297276e+00]\n",
      "  [-8.95954558e-01  2.59376822e+01  2.20020821e+01 ...  3.03964550e+00\n",
      "    3.93410005e+00  3.56281823e-01]\n",
      "  [-7.17063646e-01  1.00163910e+01  9.47971831e+00 ...  3.39742732e+00\n",
      "    4.47077279e+00  1.42962729e+00]\n",
      "  ...\n",
      "  [ 3.21853641e+00  1.16264093e+01 -1.25373638e+00 ... -4.65266370e+00\n",
      "   -9.66160923e+00 -1.16294093e+01]\n",
      "  [ 1.25073638e+00 -7.15713646e+00 -2.50597276e+00 ... -6.26268191e+00\n",
      "   -1.03771729e+01 -1.37761002e+01]\n",
      "  [ 1.25073638e+00 -6.97824555e+00 -3.59281823e-01 ... -7.15713646e+00\n",
      "   -1.10927365e+01 -1.44916638e+01]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65493461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: (1250, 19)\n"
     ]
    }
   ],
   "source": [
    "validation_data_ratio = 0.2\n",
    "# input_shape = Input(shape=input_shape)\n",
    "print('input_shape:', input_shape)\n",
    "batch_size = 128\n",
    "# n_steps = traingen.samples // BATCH_SIZE\n",
    "# n_val_steps = validgen.samples // BATCH_SIZE\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec915006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14268\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "rnd_seed = random.randint(0, 1000000)\n",
    "print(rnd_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c5ef20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Conv1D, MaxPooling2D, AveragePooling2D, AveragePooling1D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17d42992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def LSTM(input_shape, opt):\n",
    "\n",
    "    model=tf.keras.Sequential()\n",
    "    \n",
    "\n",
    "    units = 90\n",
    "    dropout_rate = 0.002 * units if units < 100 else 0.15\n",
    "\n",
    "    #model.add(Bidirectional(layers.LSTM(units,\n",
    "    #                             dropout = dropout_rate),\n",
    "    #                                                         input_shape=( time_steps, chans)\n",
    "    #))\n",
    "\n",
    "    model.add(layers.LSTM(units,\n",
    "                          input_shape=input_shape,\n",
    "                          dropout = dropout_rate,\n",
    "                         # return_sequences=True\n",
    "            ))\n",
    "    #model.add(Bidirectional(layers.LSTM(math.floor(units/2),\n",
    "    #                             dropout = dropout_rate/2)))\n",
    "    #\n",
    "    model.add(Dense(4,kernel_initializer='he_uniform',activation='relu'))\n",
    "    \n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=opt, \n",
    "          loss='binary_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a690dd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def LSTM(input_shape, opt):    \n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.LSTM(100,input_shape=input_shape))  #35 days, 51 features\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=opt, \n",
    "          loss='binary_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6020b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = opt_adam = tf.keras.optimizers.Adam(learning_rate=0.00004, \n",
    "                                beta_1=0.99,\n",
    "                                beta_2=0.999,\n",
    "                                epsilon=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca99139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_shape, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5f612364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 100)               48000     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               12928     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,057\n",
      "Trainable params: 61,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "037232f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint callback - save best weights\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath='../vgg16/V1/weights/model.weights.best.hdf5',\n",
    "                                  save_best_only=True,\n",
    "                                  verbose=1)\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_accuracy',\n",
    "                           patience=200,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e2d078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46f58bd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "29/29 [==============================] - 98s 3s/step - loss: 0.7097 - accuracy: 0.5066 - val_loss: 0.7162 - val_accuracy: 0.4957\n",
      "Epoch 2/200\n",
      "29/29 [==============================] - 101s 3s/step - loss: 0.7133 - accuracy: 0.5251 - val_loss: 0.7115 - val_accuracy: 0.4913\n",
      "Epoch 3/200\n",
      "29/29 [==============================] - 97s 3s/step - loss: 0.7012 - accuracy: 0.5295 - val_loss: 0.7072 - val_accuracy: 0.4913\n",
      "Epoch 4/200\n",
      "29/29 [==============================] - 91s 3s/step - loss: 0.6995 - accuracy: 0.5317 - val_loss: 0.7032 - val_accuracy: 0.4957\n",
      "Epoch 5/200\n",
      "29/29 [==============================] - 88s 3s/step - loss: 0.6916 - accuracy: 0.5382 - val_loss: 0.6991 - val_accuracy: 0.5087\n",
      "Epoch 6/200\n",
      "29/29 [==============================] - 90s 3s/step - loss: 0.6884 - accuracy: 0.5459 - val_loss: 0.6953 - val_accuracy: 0.5043\n",
      "Epoch 7/200\n",
      "29/29 [==============================] - 90s 3s/step - loss: 0.6825 - accuracy: 0.5688 - val_loss: 0.6916 - val_accuracy: 0.4957\n",
      "Epoch 8/200\n",
      "29/29 [==============================] - 96s 3s/step - loss: 0.6784 - accuracy: 0.5644 - val_loss: 0.6880 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "29/29 [==============================] - 88s 3s/step - loss: 0.6762 - accuracy: 0.5742 - val_loss: 0.6846 - val_accuracy: 0.5043\n",
      "Epoch 10/200\n",
      "29/29 [==============================] - 90s 3s/step - loss: 0.6678 - accuracy: 0.5590 - val_loss: 0.6816 - val_accuracy: 0.5130\n",
      "Epoch 11/200\n",
      "29/29 [==============================] - 90s 3s/step - loss: 0.6737 - accuracy: 0.5600 - val_loss: 0.6788 - val_accuracy: 0.5174\n",
      "Epoch 12/200\n",
      "29/29 [==============================] - 92s 3s/step - loss: 0.6569 - accuracy: 0.5939 - val_loss: 0.6760 - val_accuracy: 0.5130\n",
      "Epoch 13/200\n",
      "29/29 [==============================] - 96s 3s/step - loss: 0.6593 - accuracy: 0.5884 - val_loss: 0.6733 - val_accuracy: 0.5217\n",
      "Epoch 14/200\n",
      "29/29 [==============================] - 91s 3s/step - loss: 0.6579 - accuracy: 0.6004 - val_loss: 0.6709 - val_accuracy: 0.5217\n",
      "Epoch 15/200\n",
      "29/29 [==============================] - 94s 3s/step - loss: 0.6524 - accuracy: 0.5950 - val_loss: 0.6686 - val_accuracy: 0.5304\n",
      "Epoch 16/200\n",
      "29/29 [==============================] - 94s 3s/step - loss: 0.6449 - accuracy: 0.6157 - val_loss: 0.6665 - val_accuracy: 0.5391\n",
      "Epoch 17/200\n",
      "29/29 [==============================] - 94s 3s/step - loss: 0.6466 - accuracy: 0.6157 - val_loss: 0.6646 - val_accuracy: 0.5435\n",
      "Epoch 18/200\n",
      "29/29 [==============================] - 96s 3s/step - loss: 0.6400 - accuracy: 0.6070 - val_loss: 0.6630 - val_accuracy: 0.5391\n",
      "Epoch 19/200\n",
      "29/29 [==============================] - 95s 3s/step - loss: 0.6352 - accuracy: 0.6245 - val_loss: 0.6613 - val_accuracy: 0.5348\n",
      "Epoch 20/200\n",
      "29/29 [==============================] - 99s 3s/step - loss: 0.6383 - accuracy: 0.6135 - val_loss: 0.6597 - val_accuracy: 0.5391\n",
      "Epoch 21/200\n",
      "29/29 [==============================] - 97s 3s/step - loss: 0.6367 - accuracy: 0.6037 - val_loss: 0.6580 - val_accuracy: 0.5391\n",
      "Epoch 22/200\n",
      "29/29 [==============================] - 98s 3s/step - loss: 0.6230 - accuracy: 0.6332 - val_loss: 0.6564 - val_accuracy: 0.5478\n",
      "Epoch 23/200\n",
      "29/29 [==============================] - 94s 3s/step - loss: 0.6223 - accuracy: 0.6354 - val_loss: 0.6549 - val_accuracy: 0.5478\n",
      "Epoch 24/200\n",
      "29/29 [==============================] - 94s 3s/step - loss: 0.6242 - accuracy: 0.6386 - val_loss: 0.6536 - val_accuracy: 0.5478\n",
      "Epoch 25/200\n",
      "29/29 [==============================] - 97s 3s/step - loss: 0.6172 - accuracy: 0.6419 - val_loss: 0.6525 - val_accuracy: 0.5435\n",
      "Epoch 26/200\n",
      "29/29 [==============================] - 98s 3s/step - loss: 0.6194 - accuracy: 0.6419 - val_loss: 0.6514 - val_accuracy: 0.5522\n",
      "Epoch 27/200\n",
      "29/29 [==============================] - 98s 3s/step - loss: 0.6084 - accuracy: 0.6354 - val_loss: 0.6504 - val_accuracy: 0.5522\n",
      "Epoch 28/200\n",
      "29/29 [==============================] - 105s 4s/step - loss: 0.6083 - accuracy: 0.6365 - val_loss: 0.6494 - val_accuracy: 0.5522\n",
      "Epoch 29/200\n",
      "29/29 [==============================] - 108s 4s/step - loss: 0.6041 - accuracy: 0.6452 - val_loss: 0.6485 - val_accuracy: 0.5522\n",
      "Epoch 30/200\n",
      "29/29 [==============================] - 114s 4s/step - loss: 0.6015 - accuracy: 0.6386 - val_loss: 0.6477 - val_accuracy: 0.5565\n",
      "Epoch 31/200\n",
      "29/29 [==============================] - 112s 4s/step - loss: 0.5978 - accuracy: 0.6583 - val_loss: 0.6469 - val_accuracy: 0.5565\n",
      "Epoch 32/200\n",
      "29/29 [==============================] - 114s 4s/step - loss: 0.5923 - accuracy: 0.6670 - val_loss: 0.6459 - val_accuracy: 0.5565\n",
      "Epoch 33/200\n",
      "29/29 [==============================] - 116s 4s/step - loss: 0.5908 - accuracy: 0.6670 - val_loss: 0.6450 - val_accuracy: 0.5565\n",
      "Epoch 34/200\n",
      "29/29 [==============================] - 111s 4s/step - loss: 0.5945 - accuracy: 0.6419 - val_loss: 0.6442 - val_accuracy: 0.5565\n",
      "Epoch 35/200\n",
      "29/29 [==============================] - 114s 4s/step - loss: 0.5771 - accuracy: 0.6605 - val_loss: 0.6433 - val_accuracy: 0.5522\n",
      "Epoch 36/200\n",
      "29/29 [==============================] - 115s 4s/step - loss: 0.5850 - accuracy: 0.6648 - val_loss: 0.6427 - val_accuracy: 0.5522\n",
      "Epoch 37/200\n",
      "29/29 [==============================] - 113s 4s/step - loss: 0.5830 - accuracy: 0.6834 - val_loss: 0.6420 - val_accuracy: 0.5565\n",
      "Epoch 38/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.5774 - accuracy: 0.6910 - val_loss: 0.6414 - val_accuracy: 0.5652\n",
      "Epoch 39/200\n",
      "29/29 [==============================] - 106s 4s/step - loss: 0.5776 - accuracy: 0.6867 - val_loss: 0.6405 - val_accuracy: 0.5652\n",
      "Epoch 40/200\n",
      "29/29 [==============================] - 102s 4s/step - loss: 0.5673 - accuracy: 0.6987 - val_loss: 0.6398 - val_accuracy: 0.5696\n",
      "Epoch 41/200\n",
      "29/29 [==============================] - 111s 4s/step - loss: 0.5678 - accuracy: 0.6758 - val_loss: 0.6388 - val_accuracy: 0.5783\n",
      "Epoch 42/200\n",
      "29/29 [==============================] - 107s 4s/step - loss: 0.5660 - accuracy: 0.7031 - val_loss: 0.6378 - val_accuracy: 0.5783\n",
      "Epoch 43/200\n",
      "29/29 [==============================] - 108s 4s/step - loss: 0.5596 - accuracy: 0.6976 - val_loss: 0.6366 - val_accuracy: 0.5826\n",
      "Epoch 44/200\n",
      "29/29 [==============================] - 107s 4s/step - loss: 0.5585 - accuracy: 0.7183 - val_loss: 0.6354 - val_accuracy: 0.5826\n",
      "Epoch 45/200\n",
      "29/29 [==============================] - 117s 4s/step - loss: 0.5647 - accuracy: 0.7052 - val_loss: 0.6344 - val_accuracy: 0.5826\n",
      "Epoch 46/200\n",
      "29/29 [==============================] - 102s 4s/step - loss: 0.5521 - accuracy: 0.7216 - val_loss: 0.6336 - val_accuracy: 0.5826\n",
      "Epoch 47/200\n",
      "29/29 [==============================] - 101s 3s/step - loss: 0.5446 - accuracy: 0.7238 - val_loss: 0.6330 - val_accuracy: 0.5826\n",
      "Epoch 48/200\n",
      "29/29 [==============================] - 102s 4s/step - loss: 0.5493 - accuracy: 0.7227 - val_loss: 0.6325 - val_accuracy: 0.5870\n",
      "Epoch 49/200\n",
      "29/29 [==============================] - 101s 3s/step - loss: 0.5443 - accuracy: 0.7118 - val_loss: 0.6320 - val_accuracy: 0.5870\n",
      "Epoch 50/200\n",
      "29/29 [==============================] - 102s 4s/step - loss: 0.5479 - accuracy: 0.7227 - val_loss: 0.6314 - val_accuracy: 0.5870\n",
      "Epoch 51/200\n",
      "29/29 [==============================] - 103s 4s/step - loss: 0.5433 - accuracy: 0.7260 - val_loss: 0.6309 - val_accuracy: 0.5957\n",
      "Epoch 52/200\n",
      "29/29 [==============================] - 109s 4s/step - loss: 0.5434 - accuracy: 0.7249 - val_loss: 0.6303 - val_accuracy: 0.6000\n",
      "Epoch 53/200\n",
      "29/29 [==============================] - 109s 4s/step - loss: 0.5388 - accuracy: 0.7303 - val_loss: 0.6300 - val_accuracy: 0.5957\n",
      "Epoch 54/200\n",
      "29/29 [==============================] - 107s 4s/step - loss: 0.5368 - accuracy: 0.7183 - val_loss: 0.6295 - val_accuracy: 0.6000\n",
      "Epoch 55/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.5306 - accuracy: 0.7336 - val_loss: 0.6290 - val_accuracy: 0.6087\n",
      "Epoch 56/200\n",
      "29/29 [==============================] - 111s 4s/step - loss: 0.5275 - accuracy: 0.7434 - val_loss: 0.6285 - val_accuracy: 0.6130\n",
      "Epoch 57/200\n",
      "29/29 [==============================] - 107s 4s/step - loss: 0.5232 - accuracy: 0.7544 - val_loss: 0.6280 - val_accuracy: 0.6217\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 107s 4s/step - loss: 0.5309 - accuracy: 0.7413 - val_loss: 0.6276 - val_accuracy: 0.6304\n",
      "Epoch 59/200\n",
      "29/29 [==============================] - 103s 4s/step - loss: 0.5131 - accuracy: 0.7642 - val_loss: 0.6269 - val_accuracy: 0.6261\n",
      "Epoch 60/200\n",
      "29/29 [==============================] - 103s 4s/step - loss: 0.5128 - accuracy: 0.7489 - val_loss: 0.6263 - val_accuracy: 0.6348\n",
      "Epoch 61/200\n",
      "29/29 [==============================] - 107s 4s/step - loss: 0.5113 - accuracy: 0.7587 - val_loss: 0.6258 - val_accuracy: 0.6391\n",
      "Epoch 62/200\n",
      "29/29 [==============================] - 112s 4s/step - loss: 0.5115 - accuracy: 0.7620 - val_loss: 0.6255 - val_accuracy: 0.6391\n",
      "Epoch 63/200\n",
      "29/29 [==============================] - 117s 4s/step - loss: 0.5144 - accuracy: 0.7576 - val_loss: 0.6252 - val_accuracy: 0.6435\n",
      "Epoch 64/200\n",
      "29/29 [==============================] - 116s 4s/step - loss: 0.5109 - accuracy: 0.7489 - val_loss: 0.6247 - val_accuracy: 0.6478\n",
      "Epoch 65/200\n",
      "29/29 [==============================] - 117s 4s/step - loss: 0.5029 - accuracy: 0.7555 - val_loss: 0.6243 - val_accuracy: 0.6478\n",
      "Epoch 66/200\n",
      "29/29 [==============================] - 111s 4s/step - loss: 0.5052 - accuracy: 0.7598 - val_loss: 0.6238 - val_accuracy: 0.6435\n",
      "Epoch 67/200\n",
      "29/29 [==============================] - 112s 4s/step - loss: 0.5059 - accuracy: 0.7598 - val_loss: 0.6235 - val_accuracy: 0.6478\n",
      "Epoch 68/200\n",
      "29/29 [==============================] - 109s 4s/step - loss: 0.4974 - accuracy: 0.7729 - val_loss: 0.6231 - val_accuracy: 0.6522\n",
      "Epoch 69/200\n",
      "29/29 [==============================] - 111s 4s/step - loss: 0.4998 - accuracy: 0.7467 - val_loss: 0.6227 - val_accuracy: 0.6478\n",
      "Epoch 70/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.4934 - accuracy: 0.7751 - val_loss: 0.6221 - val_accuracy: 0.6522\n",
      "Epoch 71/200\n",
      "29/29 [==============================] - 109s 4s/step - loss: 0.4821 - accuracy: 0.7860 - val_loss: 0.6217 - val_accuracy: 0.6478\n",
      "Epoch 72/200\n",
      "29/29 [==============================] - 108s 4s/step - loss: 0.4928 - accuracy: 0.7707 - val_loss: 0.6212 - val_accuracy: 0.6478\n",
      "Epoch 73/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.4849 - accuracy: 0.7718 - val_loss: 0.6210 - val_accuracy: 0.6565\n",
      "Epoch 74/200\n",
      "29/29 [==============================] - 104s 4s/step - loss: 0.4765 - accuracy: 0.7904 - val_loss: 0.6207 - val_accuracy: 0.6609\n",
      "Epoch 75/200\n",
      "29/29 [==============================] - 101s 3s/step - loss: 0.4769 - accuracy: 0.7893 - val_loss: 0.6206 - val_accuracy: 0.6609\n",
      "Epoch 76/200\n",
      "29/29 [==============================] - 102s 4s/step - loss: 0.4757 - accuracy: 0.7849 - val_loss: 0.6204 - val_accuracy: 0.6609\n",
      "Epoch 77/200\n",
      "29/29 [==============================] - 109s 4s/step - loss: 0.4711 - accuracy: 0.7926 - val_loss: 0.6202 - val_accuracy: 0.6609\n",
      "Epoch 78/200\n",
      "29/29 [==============================] - 109s 4s/step - loss: 0.4707 - accuracy: 0.8002 - val_loss: 0.6199 - val_accuracy: 0.6609\n",
      "Epoch 79/200\n",
      "29/29 [==============================] - 109s 4s/step - loss: 0.4718 - accuracy: 0.7926 - val_loss: 0.6194 - val_accuracy: 0.6696\n",
      "Epoch 80/200\n",
      "29/29 [==============================] - 111s 4s/step - loss: 0.4646 - accuracy: 0.7926 - val_loss: 0.6192 - val_accuracy: 0.6652\n",
      "Epoch 81/200\n",
      "29/29 [==============================] - 111s 4s/step - loss: 0.4592 - accuracy: 0.7882 - val_loss: 0.6191 - val_accuracy: 0.6696\n",
      "Epoch 82/200\n",
      "29/29 [==============================] - 107s 4s/step - loss: 0.4612 - accuracy: 0.7926 - val_loss: 0.6190 - val_accuracy: 0.6696\n",
      "Epoch 83/200\n",
      "29/29 [==============================] - 107s 4s/step - loss: 0.4666 - accuracy: 0.7991 - val_loss: 0.6187 - val_accuracy: 0.6652\n",
      "Epoch 84/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.4616 - accuracy: 0.8035 - val_loss: 0.6184 - val_accuracy: 0.6652\n",
      "Epoch 85/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.4614 - accuracy: 0.7969 - val_loss: 0.6179 - val_accuracy: 0.6696\n",
      "Epoch 86/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.4552 - accuracy: 0.8002 - val_loss: 0.6172 - val_accuracy: 0.6696\n",
      "Epoch 87/200\n",
      "29/29 [==============================] - 109s 4s/step - loss: 0.4533 - accuracy: 0.8122 - val_loss: 0.6167 - val_accuracy: 0.6696\n",
      "Epoch 88/200\n",
      "29/29 [==============================] - 109s 4s/step - loss: 0.4494 - accuracy: 0.8133 - val_loss: 0.6162 - val_accuracy: 0.6739\n",
      "Epoch 89/200\n",
      "29/29 [==============================] - 109s 4s/step - loss: 0.4349 - accuracy: 0.8199 - val_loss: 0.6159 - val_accuracy: 0.6783\n",
      "Epoch 90/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.4350 - accuracy: 0.8133 - val_loss: 0.6158 - val_accuracy: 0.6783\n",
      "Epoch 91/200\n",
      "29/29 [==============================] - 112s 4s/step - loss: 0.4483 - accuracy: 0.8046 - val_loss: 0.6156 - val_accuracy: 0.6783\n",
      "Epoch 92/200\n",
      "29/29 [==============================] - 112s 4s/step - loss: 0.4557 - accuracy: 0.7893 - val_loss: 0.6153 - val_accuracy: 0.6783\n",
      "Epoch 93/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.4321 - accuracy: 0.8133 - val_loss: 0.6152 - val_accuracy: 0.6826\n",
      "Epoch 94/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.4276 - accuracy: 0.8210 - val_loss: 0.6150 - val_accuracy: 0.6826\n",
      "Epoch 95/200\n",
      "29/29 [==============================] - 111s 4s/step - loss: 0.4272 - accuracy: 0.8286 - val_loss: 0.6149 - val_accuracy: 0.6826\n",
      "Epoch 96/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.4317 - accuracy: 0.8242 - val_loss: 0.6146 - val_accuracy: 0.6826\n",
      "Epoch 97/200\n",
      "29/29 [==============================] - 108s 4s/step - loss: 0.4225 - accuracy: 0.8308 - val_loss: 0.6145 - val_accuracy: 0.6826\n",
      "Epoch 98/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.4165 - accuracy: 0.8242 - val_loss: 0.6147 - val_accuracy: 0.6870\n",
      "Epoch 99/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.4223 - accuracy: 0.8221 - val_loss: 0.6147 - val_accuracy: 0.6826\n",
      "Epoch 100/200\n",
      "29/29 [==============================] - 111s 4s/step - loss: 0.4115 - accuracy: 0.8450 - val_loss: 0.6146 - val_accuracy: 0.6870\n",
      "Epoch 101/200\n",
      "29/29 [==============================] - 109s 4s/step - loss: 0.4175 - accuracy: 0.8155 - val_loss: 0.6145 - val_accuracy: 0.6870\n",
      "Epoch 102/200\n",
      "29/29 [==============================] - 109s 4s/step - loss: 0.4218 - accuracy: 0.8111 - val_loss: 0.6146 - val_accuracy: 0.6826\n",
      "Epoch 103/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.4162 - accuracy: 0.8297 - val_loss: 0.6144 - val_accuracy: 0.6913\n",
      "Epoch 104/200\n",
      "29/29 [==============================] - 107s 4s/step - loss: 0.4003 - accuracy: 0.8450 - val_loss: 0.6142 - val_accuracy: 0.6870\n",
      "Epoch 105/200\n",
      "29/29 [==============================] - 108s 4s/step - loss: 0.4082 - accuracy: 0.8384 - val_loss: 0.6140 - val_accuracy: 0.6870\n",
      "Epoch 106/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.4077 - accuracy: 0.8286 - val_loss: 0.6136 - val_accuracy: 0.6913\n",
      "Epoch 107/200\n",
      "29/29 [==============================] - 110s 4s/step - loss: 0.4072 - accuracy: 0.8308 - val_loss: 0.6133 - val_accuracy: 0.6913\n",
      "Epoch 108/200\n",
      "29/29 [==============================] - 106s 4s/step - loss: 0.3901 - accuracy: 0.8483 - val_loss: 0.6128 - val_accuracy: 0.6957\n",
      "Epoch 109/200\n",
      "29/29 [==============================] - 104s 4s/step - loss: 0.4009 - accuracy: 0.8472 - val_loss: 0.6123 - val_accuracy: 0.6870\n",
      "Epoch 110/200\n",
      "29/29 [==============================] - 103s 4s/step - loss: 0.3959 - accuracy: 0.8526 - val_loss: 0.6117 - val_accuracy: 0.6870\n",
      "Epoch 111/200\n",
      "29/29 [==============================] - 102s 4s/step - loss: 0.3916 - accuracy: 0.8483 - val_loss: 0.6113 - val_accuracy: 0.6826\n",
      "Epoch 112/200\n",
      "29/29 [==============================] - 104s 4s/step - loss: 0.3953 - accuracy: 0.8373 - val_loss: 0.6108 - val_accuracy: 0.6826\n",
      "Epoch 113/200\n",
      "29/29 [==============================] - 105s 4s/step - loss: 0.3867 - accuracy: 0.8461 - val_loss: 0.6102 - val_accuracy: 0.6826\n",
      "Epoch 114/200\n",
      "29/29 [==============================] - 102s 4s/step - loss: 0.3809 - accuracy: 0.8504 - val_loss: 0.6097 - val_accuracy: 0.6826\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 103s 4s/step - loss: 0.3706 - accuracy: 0.8603 - val_loss: 0.6095 - val_accuracy: 0.6783\n",
      "Epoch 116/200\n",
      "29/29 [==============================] - 105s 4s/step - loss: 0.3869 - accuracy: 0.8548 - val_loss: 0.6094 - val_accuracy: 0.6783\n",
      "Epoch 117/200\n",
      "29/29 [==============================] - 103s 4s/step - loss: 0.3696 - accuracy: 0.8799 - val_loss: 0.6095 - val_accuracy: 0.6783\n",
      "Epoch 118/200\n",
      "29/29 [==============================] - 111s 4s/step - loss: 0.3725 - accuracy: 0.8635 - val_loss: 0.6093 - val_accuracy: 0.6783\n",
      "Epoch 119/200\n",
      "29/29 [==============================] - 119s 4s/step - loss: 0.3748 - accuracy: 0.8614 - val_loss: 0.6091 - val_accuracy: 0.6783\n",
      "Epoch 120/200\n",
      "29/29 [==============================] - 121s 4s/step - loss: 0.3724 - accuracy: 0.8701 - val_loss: 0.6088 - val_accuracy: 0.6826\n",
      "Epoch 121/200\n",
      "29/29 [==============================] - 107s 4s/step - loss: 0.3765 - accuracy: 0.8526 - val_loss: 0.6083 - val_accuracy: 0.6826\n",
      "Epoch 122/200\n",
      "29/29 [==============================] - 119s 4s/step - loss: 0.3755 - accuracy: 0.8592 - val_loss: 0.6083 - val_accuracy: 0.6826\n",
      "Epoch 123/200\n",
      "29/29 [==============================] - 118s 4s/step - loss: 0.3627 - accuracy: 0.8657 - val_loss: 0.6085 - val_accuracy: 0.6826\n",
      "Epoch 124/200\n",
      "29/29 [==============================] - 113s 4s/step - loss: 0.3543 - accuracy: 0.8777 - val_loss: 0.6091 - val_accuracy: 0.6783\n",
      "Epoch 125/200\n",
      "29/29 [==============================] - 99s 3s/step - loss: 0.3654 - accuracy: 0.8581 - val_loss: 0.6094 - val_accuracy: 0.6739\n",
      "Epoch 126/200\n",
      "29/29 [==============================] - 99s 3s/step - loss: 0.3546 - accuracy: 0.8788 - val_loss: 0.6092 - val_accuracy: 0.6739\n",
      "Epoch 127/200\n",
      "29/29 [==============================] - 101s 4s/step - loss: 0.3459 - accuracy: 0.8723 - val_loss: 0.6092 - val_accuracy: 0.6783\n",
      "Epoch 128/200\n",
      "29/29 [==============================] - 100s 3s/step - loss: 0.3489 - accuracy: 0.8734 - val_loss: 0.6089 - val_accuracy: 0.6783\n",
      "Epoch 129/200\n",
      "29/29 [==============================] - 99s 3s/step - loss: 0.3466 - accuracy: 0.8701 - val_loss: 0.6088 - val_accuracy: 0.6783\n",
      "Epoch 130/200\n",
      "29/29 [==============================] - 99s 3s/step - loss: 0.3480 - accuracy: 0.8723 - val_loss: 0.6081 - val_accuracy: 0.6826\n",
      "Epoch 131/200\n",
      "29/29 [==============================] - 99s 3s/step - loss: 0.3341 - accuracy: 0.8930 - val_loss: 0.6074 - val_accuracy: 0.6870\n",
      "Epoch 132/200\n",
      "29/29 [==============================] - 100s 3s/step - loss: 0.3424 - accuracy: 0.8810 - val_loss: 0.6067 - val_accuracy: 0.6870\n",
      "Epoch 133/200\n",
      "29/29 [==============================] - 99s 3s/step - loss: 0.3449 - accuracy: 0.8766 - val_loss: 0.6061 - val_accuracy: 0.6870\n",
      "Epoch 134/200\n",
      "29/29 [==============================] - 102s 4s/step - loss: 0.3385 - accuracy: 0.8745 - val_loss: 0.6057 - val_accuracy: 0.6870\n",
      "Epoch 135/200\n",
      "29/29 [==============================] - 106s 4s/step - loss: 0.3367 - accuracy: 0.8723 - val_loss: 0.6056 - val_accuracy: 0.6870\n",
      "Epoch 136/200\n",
      "29/29 [==============================] - 102s 4s/step - loss: 0.3260 - accuracy: 0.9007 - val_loss: 0.6058 - val_accuracy: 0.6913\n",
      "Epoch 137/200\n",
      "29/29 [==============================] - 99s 3s/step - loss: 0.3262 - accuracy: 0.8854 - val_loss: 0.6059 - val_accuracy: 0.6913\n",
      "Epoch 138/200\n",
      "29/29 [==============================] - 99s 3s/step - loss: 0.3190 - accuracy: 0.9007 - val_loss: 0.6058 - val_accuracy: 0.6913\n",
      "Epoch 139/200\n",
      "29/29 [==============================] - 97s 3s/step - loss: 0.3217 - accuracy: 0.8832 - val_loss: 0.6061 - val_accuracy: 0.6913\n",
      "Epoch 140/200\n",
      "29/29 [==============================] - 102s 4s/step - loss: 0.3225 - accuracy: 0.8865 - val_loss: 0.6061 - val_accuracy: 0.6913\n",
      "Epoch 141/200\n",
      "29/29 [==============================] - 103s 4s/step - loss: 0.3159 - accuracy: 0.8832 - val_loss: 0.6058 - val_accuracy: 0.6913\n",
      "Epoch 142/200\n",
      "29/29 [==============================] - 99s 3s/step - loss: 0.3352 - accuracy: 0.8777 - val_loss: 0.6059 - val_accuracy: 0.6957\n",
      "Epoch 143/200\n",
      "29/29 [==============================] - 100s 3s/step - loss: 0.3167 - accuracy: 0.9017 - val_loss: 0.6058 - val_accuracy: 0.7000\n",
      "Epoch 144/200\n",
      "29/29 [==============================] - 99s 3s/step - loss: 0.3170 - accuracy: 0.8886 - val_loss: 0.6057 - val_accuracy: 0.6957\n",
      "Epoch 145/200\n",
      "29/29 [==============================] - 97s 3s/step - loss: 0.3085 - accuracy: 0.9039 - val_loss: 0.6059 - val_accuracy: 0.7043\n",
      "Epoch 146/200\n",
      "29/29 [==============================] - 91s 3s/step - loss: 0.3101 - accuracy: 0.8941 - val_loss: 0.6058 - val_accuracy: 0.7000\n",
      "Epoch 147/200\n",
      "29/29 [==============================] - 85s 3s/step - loss: 0.3079 - accuracy: 0.8865 - val_loss: 0.6053 - val_accuracy: 0.7130\n",
      "Epoch 148/200\n",
      "29/29 [==============================] - 85s 3s/step - loss: 0.3114 - accuracy: 0.8908 - val_loss: 0.6053 - val_accuracy: 0.7043\n",
      "Epoch 149/200\n",
      "29/29 [==============================] - 85s 3s/step - loss: 0.3038 - accuracy: 0.9039 - val_loss: 0.6050 - val_accuracy: 0.7087\n",
      "Epoch 150/200\n",
      "29/29 [==============================] - 87s 3s/step - loss: 0.2994 - accuracy: 0.9083 - val_loss: 0.6042 - val_accuracy: 0.7087\n",
      "Epoch 151/200\n",
      "29/29 [==============================] - 87s 3s/step - loss: 0.2991 - accuracy: 0.8941 - val_loss: 0.6038 - val_accuracy: 0.7130\n",
      "Epoch 152/200\n",
      "29/29 [==============================] - 88s 3s/step - loss: 0.2966 - accuracy: 0.8876 - val_loss: 0.6036 - val_accuracy: 0.7130\n",
      "Epoch 153/200\n",
      "29/29 [==============================] - 91s 3s/step - loss: 0.2821 - accuracy: 0.9138 - val_loss: 0.6036 - val_accuracy: 0.7130\n",
      "Epoch 154/200\n",
      "29/29 [==============================] - 87s 3s/step - loss: 0.2803 - accuracy: 0.9039 - val_loss: 0.6031 - val_accuracy: 0.7130\n",
      "Epoch 155/200\n",
      "29/29 [==============================] - 87s 3s/step - loss: 0.2858 - accuracy: 0.9083 - val_loss: 0.6020 - val_accuracy: 0.7130\n",
      "Epoch 156/200\n",
      "29/29 [==============================] - 87s 3s/step - loss: 0.2907 - accuracy: 0.9028 - val_loss: 0.6007 - val_accuracy: 0.7130\n",
      "Epoch 157/200\n",
      "29/29 [==============================] - 86s 3s/step - loss: 0.2844 - accuracy: 0.9083 - val_loss: 0.6007 - val_accuracy: 0.7130\n",
      "Epoch 158/200\n",
      "29/29 [==============================] - 92s 3s/step - loss: 0.2759 - accuracy: 0.9094 - val_loss: 0.6008 - val_accuracy: 0.7130\n",
      "Epoch 159/200\n",
      "29/29 [==============================] - 89s 3s/step - loss: 0.2788 - accuracy: 0.9094 - val_loss: 0.6006 - val_accuracy: 0.7130\n",
      "Epoch 160/200\n",
      "29/29 [==============================] - 86s 3s/step - loss: 0.2777 - accuracy: 0.9170 - val_loss: 0.6003 - val_accuracy: 0.7130\n",
      "Epoch 161/200\n",
      "29/29 [==============================] - 87s 3s/step - loss: 0.2648 - accuracy: 0.9148 - val_loss: 0.6002 - val_accuracy: 0.7130\n",
      "Epoch 162/200\n",
      "29/29 [==============================] - 95s 3s/step - loss: 0.2690 - accuracy: 0.9083 - val_loss: 0.6006 - val_accuracy: 0.7130\n",
      "Epoch 163/200\n",
      "29/29 [==============================] - 89s 3s/step - loss: 0.2688 - accuracy: 0.9017 - val_loss: 0.6007 - val_accuracy: 0.7087\n",
      "Epoch 164/200\n",
      "29/29 [==============================] - 89s 3s/step - loss: 0.2675 - accuracy: 0.9192 - val_loss: 0.6014 - val_accuracy: 0.7087\n",
      "Epoch 165/200\n",
      "29/29 [==============================] - 87s 3s/step - loss: 0.2667 - accuracy: 0.9116 - val_loss: 0.6018 - val_accuracy: 0.7087\n",
      "Epoch 166/200\n",
      "29/29 [==============================] - 87s 3s/step - loss: 0.2637 - accuracy: 0.9094 - val_loss: 0.6008 - val_accuracy: 0.7087\n",
      "Epoch 167/200\n",
      "29/29 [==============================] - 86s 3s/step - loss: 0.2592 - accuracy: 0.9236 - val_loss: 0.5998 - val_accuracy: 0.7130\n",
      "Epoch 168/200\n",
      "29/29 [==============================] - 89s 3s/step - loss: 0.2639 - accuracy: 0.9170 - val_loss: 0.5990 - val_accuracy: 0.7130\n",
      "Epoch 169/200\n",
      "29/29 [==============================] - 94s 3s/step - loss: 0.2588 - accuracy: 0.9170 - val_loss: 0.5987 - val_accuracy: 0.7130\n",
      "Epoch 170/200\n",
      "29/29 [==============================] - 105s 4s/step - loss: 0.2475 - accuracy: 0.9269 - val_loss: 0.5994 - val_accuracy: 0.7174\n",
      "Epoch 171/200\n",
      "29/29 [==============================] - 106s 4s/step - loss: 0.2463 - accuracy: 0.9225 - val_loss: 0.5992 - val_accuracy: 0.7174\n",
      "Epoch 172/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 103s 4s/step - loss: 0.2488 - accuracy: 0.9279 - val_loss: 0.5993 - val_accuracy: 0.7174\n",
      "Epoch 173/200\n",
      "29/29 [==============================] - 106s 4s/step - loss: 0.2428 - accuracy: 0.9138 - val_loss: 0.5999 - val_accuracy: 0.7174\n",
      "Epoch 174/200\n",
      "29/29 [==============================] - 89s 3s/step - loss: 0.2432 - accuracy: 0.9258 - val_loss: 0.6007 - val_accuracy: 0.7174\n",
      "Epoch 175/200\n",
      "29/29 [==============================] - 99s 3s/step - loss: 0.2510 - accuracy: 0.9170 - val_loss: 0.6009 - val_accuracy: 0.7217\n",
      "Epoch 176/200\n",
      "29/29 [==============================] - 95s 3s/step - loss: 0.2346 - accuracy: 0.9356 - val_loss: 0.6005 - val_accuracy: 0.7217\n",
      "Epoch 177/200\n",
      "29/29 [==============================] - 94s 3s/step - loss: 0.2431 - accuracy: 0.9159 - val_loss: 0.5989 - val_accuracy: 0.7217\n",
      "Epoch 178/200\n",
      "29/29 [==============================] - 95s 3s/step - loss: 0.2321 - accuracy: 0.9378 - val_loss: 0.5979 - val_accuracy: 0.7217\n",
      "Epoch 179/200\n",
      "29/29 [==============================] - 96s 3s/step - loss: 0.2303 - accuracy: 0.9323 - val_loss: 0.5976 - val_accuracy: 0.7217\n",
      "Epoch 180/200\n",
      "29/29 [==============================] - 95s 3s/step - loss: 0.2227 - accuracy: 0.9345 - val_loss: 0.5971 - val_accuracy: 0.7217\n",
      "Epoch 181/200\n",
      "29/29 [==============================] - 95s 3s/step - loss: 0.2408 - accuracy: 0.9181 - val_loss: 0.5967 - val_accuracy: 0.7217\n",
      "Epoch 182/200\n",
      "29/29 [==============================] - 94s 3s/step - loss: 0.2213 - accuracy: 0.9345 - val_loss: 0.5963 - val_accuracy: 0.7174\n",
      "Epoch 183/200\n",
      "29/29 [==============================] - 95s 3s/step - loss: 0.2244 - accuracy: 0.9301 - val_loss: 0.5967 - val_accuracy: 0.7261\n",
      "Epoch 184/200\n",
      "29/29 [==============================] - 95s 3s/step - loss: 0.2082 - accuracy: 0.9443 - val_loss: 0.5979 - val_accuracy: 0.7261\n",
      "Epoch 185/200\n",
      "29/29 [==============================] - 98s 3s/step - loss: 0.2182 - accuracy: 0.9323 - val_loss: 0.5990 - val_accuracy: 0.7261\n",
      "Epoch 186/200\n",
      "29/29 [==============================] - 102s 4s/step - loss: 0.2226 - accuracy: 0.9323 - val_loss: 0.5996 - val_accuracy: 0.7348\n",
      "Epoch 187/200\n",
      "29/29 [==============================] - 96s 3s/step - loss: 0.2230 - accuracy: 0.9301 - val_loss: 0.5999 - val_accuracy: 0.7348\n",
      "Epoch 188/200\n",
      "29/29 [==============================] - 94s 3s/step - loss: 0.2106 - accuracy: 0.9389 - val_loss: 0.5997 - val_accuracy: 0.7391\n",
      "Epoch 189/200\n",
      "29/29 [==============================] - 95s 3s/step - loss: 0.2219 - accuracy: 0.9312 - val_loss: 0.5999 - val_accuracy: 0.7348\n",
      "Epoch 190/200\n",
      "29/29 [==============================] - 95s 3s/step - loss: 0.2150 - accuracy: 0.9356 - val_loss: 0.6003 - val_accuracy: 0.7348\n",
      "Epoch 191/200\n",
      "29/29 [==============================] - 96s 3s/step - loss: 0.2129 - accuracy: 0.9345 - val_loss: 0.6006 - val_accuracy: 0.7391\n",
      "Epoch 192/200\n",
      "29/29 [==============================] - 94s 3s/step - loss: 0.2008 - accuracy: 0.9421 - val_loss: 0.5998 - val_accuracy: 0.7391\n",
      "Epoch 193/200\n",
      "29/29 [==============================] - 94s 3s/step - loss: 0.2086 - accuracy: 0.9421 - val_loss: 0.5997 - val_accuracy: 0.7391\n",
      "Epoch 194/200\n",
      "29/29 [==============================] - 92s 3s/step - loss: 0.2035 - accuracy: 0.9400 - val_loss: 0.5991 - val_accuracy: 0.7391\n",
      "Epoch 195/200\n",
      "29/29 [==============================] - 95s 3s/step - loss: 0.2043 - accuracy: 0.9400 - val_loss: 0.5983 - val_accuracy: 0.7391\n",
      "Epoch 196/200\n",
      "29/29 [==============================] - 94s 3s/step - loss: 0.1964 - accuracy: 0.9585 - val_loss: 0.5969 - val_accuracy: 0.7348\n",
      "Epoch 197/200\n",
      "29/29 [==============================] - 96s 3s/step - loss: 0.1971 - accuracy: 0.9443 - val_loss: 0.5962 - val_accuracy: 0.7348\n",
      "Epoch 198/200\n",
      "29/29 [==============================] - 93s 3s/step - loss: 0.1911 - accuracy: 0.9509 - val_loss: 0.5956 - val_accuracy: 0.7348\n",
      "Epoch 199/200\n",
      "29/29 [==============================] - 94s 3s/step - loss: 0.1927 - accuracy: 0.9476 - val_loss: 0.5956 - val_accuracy: 0.7348\n",
      "Epoch 200/200\n",
      "29/29 [==============================] - 93s 3s/step - loss: 0.1943 - accuracy: 0.9421 - val_loss: 0.5960 - val_accuracy: 0.7348\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train.reshape(-1,1),\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    epochs=200, \n",
    "#     callbacks=[tl_checkpoint_1, early_stop],\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7370eec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "116/116 [==============================] - 76s 648ms/step - loss: 0.7079 - accuracy: 0.5236 - val_loss: 0.7047 - val_accuracy: 0.5325\n",
      "Epoch 2/300\n",
      "116/116 [==============================] - 74s 641ms/step - loss: 0.6898 - accuracy: 0.5566 - val_loss: 0.6864 - val_accuracy: 0.5584\n",
      "Epoch 3/300\n",
      "116/116 [==============================] - 74s 635ms/step - loss: 0.6775 - accuracy: 0.5734 - val_loss: 0.6710 - val_accuracy: 0.5639\n",
      "Epoch 4/300\n",
      "116/116 [==============================] - 74s 635ms/step - loss: 0.6633 - accuracy: 0.5861 - val_loss: 0.6581 - val_accuracy: 0.5790\n",
      "Epoch 5/300\n",
      "116/116 [==============================] - 76s 653ms/step - loss: 0.6513 - accuracy: 0.6073 - val_loss: 0.6469 - val_accuracy: 0.5974\n",
      "Epoch 6/300\n",
      "116/116 [==============================] - 77s 660ms/step - loss: 0.6400 - accuracy: 0.6154 - val_loss: 0.6366 - val_accuracy: 0.6028\n",
      "Epoch 7/300\n",
      "116/116 [==============================] - 77s 661ms/step - loss: 0.6354 - accuracy: 0.6138 - val_loss: 0.6275 - val_accuracy: 0.6158\n",
      "Epoch 8/300\n",
      "116/116 [==============================] - 77s 662ms/step - loss: 0.6221 - accuracy: 0.6270 - val_loss: 0.6200 - val_accuracy: 0.6310\n",
      "Epoch 9/300\n",
      "116/116 [==============================] - 74s 642ms/step - loss: 0.6144 - accuracy: 0.6308 - val_loss: 0.6128 - val_accuracy: 0.6418\n",
      "Epoch 10/300\n",
      "116/116 [==============================] - 75s 644ms/step - loss: 0.6052 - accuracy: 0.6446 - val_loss: 0.6060 - val_accuracy: 0.6450\n",
      "Epoch 11/300\n",
      "116/116 [==============================] - 74s 640ms/step - loss: 0.5974 - accuracy: 0.6644 - val_loss: 0.5995 - val_accuracy: 0.6580\n",
      "Epoch 12/300\n",
      "116/116 [==============================] - 73s 628ms/step - loss: 0.5928 - accuracy: 0.6631 - val_loss: 0.5936 - val_accuracy: 0.6667\n",
      "Epoch 13/300\n",
      "116/116 [==============================] - 72s 621ms/step - loss: 0.5861 - accuracy: 0.6752 - val_loss: 0.5882 - val_accuracy: 0.6699\n",
      "Epoch 14/300\n",
      "116/116 [==============================] - 72s 617ms/step - loss: 0.5770 - accuracy: 0.6931 - val_loss: 0.5835 - val_accuracy: 0.6732\n",
      "Epoch 15/300\n",
      "116/116 [==============================] - 71s 615ms/step - loss: 0.5712 - accuracy: 0.6947 - val_loss: 0.5787 - val_accuracy: 0.6818\n",
      "Epoch 16/300\n",
      "116/116 [==============================] - 72s 622ms/step - loss: 0.5626 - accuracy: 0.6999 - val_loss: 0.5741 - val_accuracy: 0.6861\n",
      "Epoch 17/300\n",
      "116/116 [==============================] - 70s 605ms/step - loss: 0.5579 - accuracy: 0.7067 - val_loss: 0.5701 - val_accuracy: 0.6937\n",
      "Epoch 18/300\n",
      "116/116 [==============================] - 69s 598ms/step - loss: 0.5589 - accuracy: 0.7102 - val_loss: 0.5658 - val_accuracy: 0.6970\n",
      "Epoch 19/300\n",
      "116/116 [==============================] - 72s 618ms/step - loss: 0.5485 - accuracy: 0.7132 - val_loss: 0.5617 - val_accuracy: 0.7024\n",
      "Epoch 20/300\n",
      "116/116 [==============================] - 69s 592ms/step - loss: 0.5399 - accuracy: 0.7278 - val_loss: 0.5578 - val_accuracy: 0.7035\n",
      "Epoch 21/300\n",
      "116/116 [==============================] - 69s 599ms/step - loss: 0.5373 - accuracy: 0.7226 - val_loss: 0.5539 - val_accuracy: 0.7089\n",
      "Epoch 22/300\n",
      "116/116 [==============================] - 70s 602ms/step - loss: 0.5338 - accuracy: 0.7262 - val_loss: 0.5504 - val_accuracy: 0.7110\n",
      "Epoch 23/300\n",
      "116/116 [==============================] - 69s 599ms/step - loss: 0.5293 - accuracy: 0.7316 - val_loss: 0.5467 - val_accuracy: 0.7100\n",
      "Epoch 24/300\n",
      "116/116 [==============================] - 69s 598ms/step - loss: 0.5192 - accuracy: 0.7400 - val_loss: 0.5430 - val_accuracy: 0.7132\n",
      "Epoch 25/300\n",
      "116/116 [==============================] - 71s 612ms/step - loss: 0.5148 - accuracy: 0.7440 - val_loss: 0.5387 - val_accuracy: 0.7197\n",
      "Epoch 26/300\n",
      "116/116 [==============================] - 69s 596ms/step - loss: 0.5138 - accuracy: 0.7413 - val_loss: 0.5342 - val_accuracy: 0.7251\n",
      "Epoch 27/300\n",
      "116/116 [==============================] - 69s 599ms/step - loss: 0.5052 - accuracy: 0.7614 - val_loss: 0.5306 - val_accuracy: 0.7294\n",
      "Epoch 28/300\n",
      "116/116 [==============================] - 70s 604ms/step - loss: 0.5023 - accuracy: 0.7557 - val_loss: 0.5269 - val_accuracy: 0.7305\n",
      "Epoch 29/300\n",
      "116/116 [==============================] - 69s 594ms/step - loss: 0.4963 - accuracy: 0.7551 - val_loss: 0.5229 - val_accuracy: 0.7305\n",
      "Epoch 30/300\n",
      "116/116 [==============================] - 70s 602ms/step - loss: 0.4895 - accuracy: 0.7660 - val_loss: 0.5193 - val_accuracy: 0.7370\n",
      "Epoch 31/300\n",
      "116/116 [==============================] - 70s 606ms/step - loss: 0.4851 - accuracy: 0.7646 - val_loss: 0.5163 - val_accuracy: 0.7392\n",
      "Epoch 32/300\n",
      "116/116 [==============================] - 68s 589ms/step - loss: 0.4856 - accuracy: 0.7698 - val_loss: 0.5135 - val_accuracy: 0.7392\n",
      "Epoch 33/300\n",
      "116/116 [==============================] - 70s 603ms/step - loss: 0.4740 - accuracy: 0.7760 - val_loss: 0.5109 - val_accuracy: 0.7403\n",
      "Epoch 34/300\n",
      "116/116 [==============================] - 69s 599ms/step - loss: 0.4683 - accuracy: 0.7784 - val_loss: 0.5073 - val_accuracy: 0.7424\n",
      "Epoch 35/300\n",
      "116/116 [==============================] - 68s 585ms/step - loss: 0.4676 - accuracy: 0.7860 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
      "Epoch 36/300\n",
      "116/116 [==============================] - 70s 602ms/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.5011 - val_accuracy: 0.7511\n",
      "Epoch 37/300\n",
      "116/116 [==============================] - 68s 591ms/step - loss: 0.4557 - accuracy: 0.7863 - val_loss: 0.4989 - val_accuracy: 0.7532\n",
      "Epoch 38/300\n",
      "116/116 [==============================] - 68s 587ms/step - loss: 0.4511 - accuracy: 0.7874 - val_loss: 0.4965 - val_accuracy: 0.7543\n",
      "Epoch 39/300\n",
      "116/116 [==============================] - 70s 605ms/step - loss: 0.4506 - accuracy: 0.7871 - val_loss: 0.4938 - val_accuracy: 0.7576\n",
      "Epoch 40/300\n",
      "116/116 [==============================] - 69s 596ms/step - loss: 0.4382 - accuracy: 0.8061 - val_loss: 0.4907 - val_accuracy: 0.7532\n",
      "Epoch 41/300\n",
      "116/116 [==============================] - 67s 581ms/step - loss: 0.4336 - accuracy: 0.8007 - val_loss: 0.4882 - val_accuracy: 0.7522\n",
      "Epoch 42/300\n",
      "116/116 [==============================] - 69s 597ms/step - loss: 0.4302 - accuracy: 0.8050 - val_loss: 0.4858 - val_accuracy: 0.7511\n",
      "Epoch 43/300\n",
      "116/116 [==============================] - 68s 586ms/step - loss: 0.4297 - accuracy: 0.8109 - val_loss: 0.4839 - val_accuracy: 0.7565\n",
      "Epoch 44/300\n",
      "116/116 [==============================] - 67s 578ms/step - loss: 0.4220 - accuracy: 0.8142 - val_loss: 0.4807 - val_accuracy: 0.7554\n",
      "Epoch 45/300\n",
      "116/116 [==============================] - 67s 577ms/step - loss: 0.4152 - accuracy: 0.8161 - val_loss: 0.4785 - val_accuracy: 0.7587\n",
      "Epoch 46/300\n",
      "116/116 [==============================] - 64s 548ms/step - loss: 0.4168 - accuracy: 0.8166 - val_loss: 0.4762 - val_accuracy: 0.7619\n",
      "Epoch 47/300\n",
      "116/116 [==============================] - 60s 515ms/step - loss: 0.4077 - accuracy: 0.8223 - val_loss: 0.4751 - val_accuracy: 0.7608\n",
      "Epoch 48/300\n",
      "116/116 [==============================] - 60s 516ms/step - loss: 0.4022 - accuracy: 0.8237 - val_loss: 0.4725 - val_accuracy: 0.7662\n",
      "Epoch 49/300\n",
      "116/116 [==============================] - 60s 516ms/step - loss: 0.3978 - accuracy: 0.8250 - val_loss: 0.4701 - val_accuracy: 0.7706\n",
      "Epoch 50/300\n",
      "116/116 [==============================] - 60s 515ms/step - loss: 0.3899 - accuracy: 0.8258 - val_loss: 0.4667 - val_accuracy: 0.7738\n",
      "Epoch 51/300\n",
      "116/116 [==============================] - 59s 509ms/step - loss: 0.3857 - accuracy: 0.8296 - val_loss: 0.4643 - val_accuracy: 0.7738\n",
      "Epoch 52/300\n",
      "116/116 [==============================] - 59s 508ms/step - loss: 0.3813 - accuracy: 0.8378 - val_loss: 0.4631 - val_accuracy: 0.7738\n",
      "Epoch 53/300\n",
      "116/116 [==============================] - 59s 512ms/step - loss: 0.3778 - accuracy: 0.8386 - val_loss: 0.4606 - val_accuracy: 0.7792\n",
      "Epoch 54/300\n",
      "116/116 [==============================] - 59s 509ms/step - loss: 0.3767 - accuracy: 0.8378 - val_loss: 0.4579 - val_accuracy: 0.7825\n",
      "Epoch 55/300\n",
      "116/116 [==============================] - 59s 509ms/step - loss: 0.3721 - accuracy: 0.8364 - val_loss: 0.4548 - val_accuracy: 0.7857\n",
      "Epoch 56/300\n",
      " 73/116 [=================>............] - ETA: 20s - loss: 0.3725 - accuracy: 0.8416"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train.reshape(-1,1),\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    epochs=300, \n",
    "#     callbacks=[tl_checkpoint_1, early_stop],\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cf5c5233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "116/116 [==============================] - 78s 659ms/step - loss: 0.7209 - accuracy: 0.4764 - val_loss: 0.6862 - val_accuracy: 0.5411\n",
      "Epoch 2/300\n",
      "116/116 [==============================] - 80s 690ms/step - loss: 0.6908 - accuracy: 0.5460 - val_loss: 0.6711 - val_accuracy: 0.5714\n",
      "Epoch 3/300\n",
      "116/116 [==============================] - 88s 763ms/step - loss: 0.6777 - accuracy: 0.5734 - val_loss: 0.6605 - val_accuracy: 0.5942\n",
      "Epoch 4/300\n",
      "116/116 [==============================] - 89s 772ms/step - loss: 0.6678 - accuracy: 0.5804 - val_loss: 0.6529 - val_accuracy: 0.6006\n",
      "Epoch 5/300\n",
      "116/116 [==============================] - 99s 849ms/step - loss: 0.6553 - accuracy: 0.6018 - val_loss: 0.6460 - val_accuracy: 0.6028\n",
      "Epoch 6/300\n",
      "116/116 [==============================] - 100s 865ms/step - loss: 0.6527 - accuracy: 0.6035 - val_loss: 0.6399 - val_accuracy: 0.6082\n",
      "Epoch 7/300\n",
      "116/116 [==============================] - 103s 887ms/step - loss: 0.6453 - accuracy: 0.6132 - val_loss: 0.6334 - val_accuracy: 0.6158\n",
      "Epoch 8/300\n",
      "116/116 [==============================] - 106s 919ms/step - loss: 0.6372 - accuracy: 0.6211 - val_loss: 0.6270 - val_accuracy: 0.6234\n",
      "Epoch 9/300\n",
      "116/116 [==============================] - 105s 906ms/step - loss: 0.6272 - accuracy: 0.6414 - val_loss: 0.6206 - val_accuracy: 0.6342\n",
      "Epoch 10/300\n",
      "116/116 [==============================] - 106s 915ms/step - loss: 0.6215 - accuracy: 0.6463 - val_loss: 0.6145 - val_accuracy: 0.6450\n",
      "Epoch 11/300\n",
      "116/116 [==============================] - 97s 835ms/step - loss: 0.6162 - accuracy: 0.6411 - val_loss: 0.6087 - val_accuracy: 0.6526\n",
      "Epoch 12/300\n",
      "116/116 [==============================] - 95s 815ms/step - loss: 0.6083 - accuracy: 0.6495 - val_loss: 0.6032 - val_accuracy: 0.6613\n",
      "Epoch 13/300\n",
      "116/116 [==============================] - 99s 858ms/step - loss: 0.6027 - accuracy: 0.6585 - val_loss: 0.5976 - val_accuracy: 0.6667\n",
      "Epoch 14/300\n",
      "116/116 [==============================] - 104s 901ms/step - loss: 0.5929 - accuracy: 0.6677 - val_loss: 0.5924 - val_accuracy: 0.6699\n",
      "Epoch 15/300\n",
      "116/116 [==============================] - 101s 875ms/step - loss: 0.5856 - accuracy: 0.6853 - val_loss: 0.5869 - val_accuracy: 0.6807\n",
      "Epoch 16/300\n",
      "116/116 [==============================] - 98s 841ms/step - loss: 0.5795 - accuracy: 0.6831 - val_loss: 0.5817 - val_accuracy: 0.6797\n",
      "Epoch 17/300\n",
      "116/116 [==============================] - 101s 872ms/step - loss: 0.5729 - accuracy: 0.6958 - val_loss: 0.5768 - val_accuracy: 0.6840\n",
      "Epoch 18/300\n",
      "116/116 [==============================] - 96s 829ms/step - loss: 0.5672 - accuracy: 0.6939 - val_loss: 0.5720 - val_accuracy: 0.6851\n",
      "Epoch 19/300\n",
      "116/116 [==============================] - 95s 823ms/step - loss: 0.5625 - accuracy: 0.6999 - val_loss: 0.5677 - val_accuracy: 0.6894\n",
      "Epoch 20/300\n",
      "116/116 [==============================] - 96s 827ms/step - loss: 0.5583 - accuracy: 0.7042 - val_loss: 0.5633 - val_accuracy: 0.6905\n",
      "Epoch 21/300\n",
      "116/116 [==============================] - 96s 832ms/step - loss: 0.5463 - accuracy: 0.7178 - val_loss: 0.5592 - val_accuracy: 0.6916\n",
      "Epoch 22/300\n",
      "116/116 [==============================] - 99s 855ms/step - loss: 0.5470 - accuracy: 0.7077 - val_loss: 0.5544 - val_accuracy: 0.6905\n",
      "Epoch 23/300\n",
      " 12/116 [==>...........................] - ETA: 1:21 - loss: 0.5332 - accuracy: 0.7135"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'while/split' defined at (most recent call last):\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\dt\\AppData\\Local\\Temp\\ipykernel_22808\\1805895235.py\", line 1, in <cell line: 1>\n      history = model.fit(\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\", line 515, in __call__\n      return super(RNN, self).__call__(inputs, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 673, in call\n      runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 1183, in lstm_with_backend_selection\n      last_output, outputs, new_h, new_c, runtime = defun_standard_lstm(**params)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 891, in standard_lstm\n      last_output, outputs, new_states = backend.rnn(\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\backend.py\", line 4776, in rnn\n      final_outputs = tf.compat.v1.while_loop(\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\backend.py\", line 4759, in _step\n      output, new_states = step_function(current_input,\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 881, in step\n      z0, z1, z2, z3 = tf.split(z, 4, axis=1)\nNode: 'while/split'\nOOM when allocating tensor with shape[32,100] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node while/split}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[sequential_1/lstm_1/PartitionedCall]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_40777]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;43;03m#     callbacks=[tl_checkpoint_1, early_stop],\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mE:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'while/split' defined at (most recent call last):\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\dt\\AppData\\Local\\Temp\\ipykernel_22808\\1805895235.py\", line 1, in <cell line: 1>\n      history = model.fit(\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\", line 515, in __call__\n      return super(RNN, self).__call__(inputs, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 673, in call\n      runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 1183, in lstm_with_backend_selection\n      last_output, outputs, new_h, new_c, runtime = defun_standard_lstm(**params)\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 891, in standard_lstm\n      last_output, outputs, new_states = backend.rnn(\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\backend.py\", line 4776, in rnn\n      final_outputs = tf.compat.v1.while_loop(\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\backend.py\", line 4759, in _step\n      output, new_states = step_function(current_input,\n    File \"E:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 881, in step\n      z0, z1, z2, z3 = tf.split(z, 4, axis=1)\nNode: 'while/split'\nOOM when allocating tensor with shape[32,100] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node while/split}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n\n\t [[sequential_1/lstm_1/PartitionedCall]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_40777]"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train.reshape(-1,1),\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    epochs=300, \n",
    "#     callbacks=[tl_checkpoint_1, early_stop],\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "514a3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('../vgg16/V1/model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6103a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8ee989bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9df3c63f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_accuracy(\u001b[43mhistory\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a636b43",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_loss(\u001b[43mhistory\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba19b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4314a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b88da262",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([0 if x < 0.5 else 1 for x in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aca1cb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n",
      "287\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "264f1f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 1 0 1 1 1 0 0 0 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0:15])\n",
    "print(y_test[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "48088fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5470383275261324\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "232d80a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAEJCAYAAACqmv3eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgPklEQVR4nO3deXhV1b3/8fc3CSEBlEESxIAMggxO4IADaq1UpTiAHbxqbUG5pa1jr/ooalurrdX219r6q20tVgVah2udACsKUq0TgyjKqAKCkgQJKCBjQsj3/nEO8RBPTk7CSXb2zufFs5+cs9faay+mT1bWXnsfc3dERKTpZQXdARGRlkoBLCISEAWwiEhAFMAiIgFRAIuIBEQBLCISEAWwiEhAFMAhZWZexzZxH9r+uZktrkf9XDNbb2ZbzKx9Q88r0tLkBN0BabCuCa/PAe6vsW9HE/ZlFLAK2AxcDPylCc/9JWaW6+4VQfZBJB0aAYeUu3+yZwM2Jdl3qpm9ZWY7zWyVmd1hZrl7jjezb5jZQjPbYWafmdl/zKyLmY0BbgUOSxhNj6mjO2OBvwOT46/3YmYHmdnDZvapmW03s3fM7KsJ5Web2dx4Xz41s2lmlhcvW21m19do72Uzuzfh/er4qP1BM9sEPBzff5eZvR9vd7WZ/WZPu3Wd28x+luynADN73cz+fx1/HiJp0Qg4gszsLGIhdA3wCnAwcB/QGrjezA4EHgNuAp4E2gEnxA//X+BwYqPq0+L7Nqc4V494vUuA7cBfzGyQu78TL28L/AcoA84HSoCjEo4fDkwB7gIuJfZv8kzqPzi4FvglcCxg8X3bgMvi5xwY/zMoB36axrkfBH5mZkPcfV68fj/gJODyevZNJDl31xbyDfhW7K+y+v0rwE9r1BkFbCUWTkcDDvSopb2fA4vTPPdtwLMJ7ycDf0x4/31gC9C5luNfBx5L0f5q4Poa+14G7q1RZ1oaff0hsKIe534WuC/h/a+B+UH/fWuLzqYpiGg6BrjFzLbu2YBHgLbAgcC7wIvAYjN70sx+ZGYF9T2JmWUBY4hNP+zxd+A7CT/qDwYWuvuGWpoZDMyq77mTmJ+kf98ys9fM7JP4n8Hvif00kO657wcuNLN8M8sGvgs8kIG+igCaA46qLGIj00EJ25FAX2C9u+8m9qP2mcBCYvO2y83sqCRtpXImsUB72MwqzawSmA50BL4Zr2O1HZymqiRttEpSb1viGzM7gdg0ywvAucTC9ie1HFubfxGbVvkmMALoADxaj+NFUlIAR9PbQH93X5Fkq4TYfIW7z3b324DjgFLgv+LHVwDZaZxnLPAUewf9IGIjxz0X494GjjSzzrW0sQAYluIc60lY3REfWfdPo29DgRJ3/4W7v+nuy4Ee9Tl3/M9qIrF55MuAp9x9UxrnFkmLLsJF0+3As2b2EfA4UEnswtoQd78hPjr8GrHR4Tpio8PuwNL48auBHmZ2NPAxsMXdyxNPEA/U84Bvu/viGmUPALPN7BBiUx/jgWfM7CagGDgi3uZLwB3ANDNbEa9rxEbWf3X37cC/gcvMbCqxML6F9EaxHwBFZvYdYDZwFnBRjTp1nRvgb8CNxEbiZ6ZxXpH0BT0JrW3fN2pchIvvOxN4ldiP0J8TmyO9Ml42gNhUwTpiqwJWADckHNsaeALYSOxi3Zgk57w23m7rWvr0EfCr+OtuxFZXbIr3ZwFwWkLd84C34n3ZAEwF8uJl+xP7sX8zsdUMl5P8Itz1SfpwJ7HQ3kpspP6jJH9OtZ47oc6/gZWABf13rS1am7nrEzFEUjGzpcDD7n5H0H2RaNEUhEgtzKyQ2LRFT+CvwfZGokgBLFK7dcSmJX7gtS+jE2kwTUGIiAREy9BERALS6FMQOyvREFu+pOgy3c8gX/bp5Iv29cYd8gdfmXbm7Fhw7z6fb19oDlhEosXC84O9AlhEosUCHdTWiwJYRKJFI2ARkYBoBCwiEpCsdJ4j1TwogEUkWjQFISISEE1BiIgERCNgEZGAaAQsIhIQjYBFRAKiVRAiIgHRCFhEJCBZmgMWEQmGRsAiIgHRKggRkYDoIpyISEA0BSEiEhBNQYiIBEQjYBGRgIRoBByebxUiIumwrPS3upoye9DMysxscZKy683Mzaxzwr6bzGyFmb1vZmfV1b4CWESiJSs7/a1uE4HhNXeaWXfgDODjhH0DgQuBw+LH/NnMUp5EASwi0ZLBEbC7vwJ8lqTo98ANgCfsGwk85u7l7r4KWAEMSdW+AlhEosUs7c3MxpnZ/IRtXN3N23lAibu/W6OoCFiT8L44vq9WuggnItFSj1UQ7j4BmJB202ZtgFuAM5MVJztFqvYUwCISLY27CuIQoBfwrsXO0w1428yGEBvxdk+o2w0oTdWYpiBEJFoyOAdck7svcvdCd+/p7j2Jhe7R7v4JMBW40Mxam1kvoC8wL1V7CmARiRTLykp7q7Mts0eB2UA/Mys2s7G11XX3JcDjwFLgeeAKd9+dqn1NQYhIpFgGpyDc/aI6ynvWeH8HcEe67SuARSRawnMjnAJYRKIlkyPgxqYAFpFIUQCLiAQkK42La82FAlhEoiU8A2AFsIhEi6YgREQCogAWEQmIAlhEJCAKYBGRgFiWAlhEJBAaAYuIBEQBLCISlPDkrwJYRKJFI2ARkYAogKXatm1bmTzxIV6cOYOS4mKys7Po0aMnZ404m4svvoRWublBd1HqIT83m5P6FzKoZyeO7NmRo3p2onvntgD8+ulF/ObpxbUee1K/Ar56RFcG9epEj4J2HLBfa9q2zmHT9greK97Mc28VM/nllezclfIZ3vQsbMdVIwbw1SMOpEv7fLbs3MWijzYy+aUVTJtfnNHfbxjpWRACQGlpCWPHfJfSkhIA8vLzqaioYMmSxSxZspjnnp3G/Q9MZP/27QPuqaTr6N4H8Pj1pzXo2CvPHsBZg774kNytO3dRXrmbgv3zKBiYxykDu/CDs/pxwW9fZuUnW5K28bUju/LgVSfTtnXsv+7n2yvo1C6X04/oyulHdOXhVz7k6r/NbVD/IiM8A2AFcGPZvXs3V1/xQ0pLSigoKOCXd/6GE048iaqqKma88Dy33/oT3lu2lJtuvJ4/3Xd/0N2Veti4tZyFH23k3dUbWbj6M375naM5sEN+ncf9Z8k6Xlq0ljkfbGDVui1s3VkJQMd2uXzrxB787IJB9Cxsx+SrT+HkW57Da3ye7sGd2/LAlUNp2zqHOR+s5+q/zWXlJ1to2zqHK0f054bzj+A7p/Zmeenn/PG5ZY3xWw8FTUEIU555iuUffADA7/7wR44aNBiI/Xg0/Osj8Koqxt9wHa+9+gpz58zm+BNODLK7kqbZ76+nz+VP7bXvZxccldaxf33h/aT7N26t4P6ZyynfVcXvLxtC/27tOa5PZ+Yt37BXvZu+eQTt8lrxyaYdXHT3f/h8+y4AtpVX8uunF1PYPp8xp/fh2vMGMvnlFWyOl7c0mQxgM3sQOAcoc/fD4/v+H3AuUAGsBC51903xspuAscBu4Gp3fyFV++GZLAmZaVOeAeC4IcdXh2+i4SPOpqhbt73qSvNXVXNYmkHzV35a/fqgTm32KmuTm805x8Y+8fyhWcurwzfRH55dCsD+bXI5+5hujdbP5s7M0t7SMBEYXmPfTOBwdz8S+AC4KX7egcCFwGHxY/5sZtmpGlcAN4IdO3bwzoK3ATj5lFOT1jEzhg49BYDZb7zeZH2T5uvEQwuqX68u27pX2fH9CmgTn/edtXBt0uPXbNjG+yWbATjt8K6N1Mvmz7Is7a0u7v4K8FmNfTPcvTL+dg6w57vdSOAxdy9391XACmBIqvYVwI1g1YcrqaqqAqBP37611ttTtmHDejZv2tQUXZNmJq9VNr27tON/zh3I7RfFflJ6/b0y3lm11/95BhR1qH79Xjxkk1lWHCvrX9RyL+xmeARcl8uA6fHXRcCahLLi+L5aaQ64EZSVlVW/LizsUmu9wi5flJWtL6N9hw6N2S1pJgrb57Hsj+cnLZv+djFX3v/lVQwHdoxd5Nu4tZwdFbUvU1u7cfte9Vui+gSrmY0DxiXsmuDuE9I89hagEnh4z64k1VLOWSmAG8H2bduqX+fl1f4fIbEs8RiJtt1VzrpNOwDYv00r8nNj/w2fmfsxdz21kE3bKr50TLu8WJ1U4ZtYvqd+S1SfAI6HbVqBW+Mco4ldnBvmXn1hoBjonlCtG1Caqp06/5bMrD+xuY0iYmleCkx195a7zkVkH3y6pZyBVz9T/f6gjrHVC5d/vT8jjinixslvMfnllcF1MOwaeRWamQ0HbgS+4u7bE4qmAo+Y2d3AQUBfYF6qtlLOAZvZjcBjxH5L84A3468fNbPxKY4bZ2bzzWz+A/fX+5tL6LVp27b69c6dO2qtl1iWeIy0LKUbd/CrJxfxw/tmk5uTzW/HHMth3TvsVWfPmuH83JQX1avL99RviTI5B2xmjwKzgX5mVmxmY4F7gf2AmWb2jpndB+DuS4DHgaXA88AV7p7yR5a6RsBjgcPcfa81L/GEXwLcleygxGH9zsrUcyBRVFhYWP26rGwdh/brn7Re2bp1XxxTUJi0jrQcz84v5uP1Wzm4oB2XfKU3N/3j7eqyTzbGvll3bNea/NzsWqciunZss1f9ligrgw9kd/eLkux+IEX9O4A70m2/rlUQVcSG0jV1jZdJEr16H1J9P/qK5ctrrbenrHPnAl2AEwA+ic8N9+qy3177l5Vsqn6daoXDgG6xslQrJaKuiVdB7JO6AvjHwCwzm25mE+Lb88As4JpG711I5efnM2jw0QC8/tqrSeu4O2+88RoAJ540tMn6Js3bwQXtgNhzIhLNfX8928tj0wqnH5l8jW+3A9rQLx7OLy9Ovla4JTBLfwtaygB29+eBQ4HbgBeAGcDPgX7xMqnFuSNHAfDmvLksXPjul8pnvDCd4jVr9qor0ZWdxo/FF5/au/qZEq8vK9urbHvFbp6dH/v3ctnpfdgvv9WXjr/mnIEAbNmxi3+91XKfihalETDuXuXuc9z9SXd/Iv469VoY4byR59P30ENxd6778VXMnTMbIP4wnuncfutPgdidcnoORLi0b9OKTu1yq7c9c475uTl77d/zxDKAEw4tYNrNw7jgpJ4cVGONbu8u7fjZBUdx95jjAPhw3RYefXXVl85755OL2LpzFwd2bMMj/3MqvbvERsttcrO5fuRhjPlqHwB+N2VJi30OBIRrBGzeiPe2Q8u8CLdHSUkx/33p9/Z6HKVXVVFeXg5A/wEDW+zjKIsuezToLjTYgt+dWz1VkMqjr35YfVPF0P6FTL15WHXZjopKtu2spE3rnOpbjAEWfbSR797zKms2JF8XXvNxlJu3VdA2L4ec7NhY6pFXPuSqED+O8tPJF+1zLA68eUbambP0V2cGGsMtd7V2Eygq6sYTT09l0kMPMuvFmbEHsufkcEifPgwfcY4eyN6CvLv6M35032yGDijkqJ6dKGyfR6d2rSmv3M2H67awcPVGps1fw9R5a1I+8OfFhWs59ZbpXH32AE47/EAO7JDP5u27WLj6MybpgexAZldBNDaNgCUQYR4BS+PJxAj4iJ/OTDtzFv3iDI2ARUQypTlcXEuXAlhEIkUBLCISkBDlrwJYRKIlTBfhFMAiEimaghARCUiI8lcBLCLRohGwiEhAQpS/CmARiRaNgEVEAqJVECIiAQnRAFgBLCLREqYpiDqfBywiEiaZfB6wmT1oZmVmtjhhXyczm2lmy+NfOyaU3WRmK8zsfTM7q672FcAiEikZ/kSMicDwGvvGA7PcvS+xj2cbHz/vQOBC4LD4MX82s5QfY60AFpFIyWQAu/srwGc1do8EJsVfTwJGJex/zN3L3X0VsAIYkqp9BbCIREpWlqW9mdk4M5ufsI1L4xRd3H0tQPxrYXx/EbAmoV5xfF+tdBFORCKlPtfg3H0CMCFTp052ilQHKIBFJFKaYBXEOjPr6u5rzawrsOcjrIuB7gn1ugGlqRrSFISIREoTfCryVGB0/PVoYErC/gvNrLWZ9QL6AvNSNaQRsIhESlYGR8Bm9ihwGtDZzIqBW4G7gMfNbCzwMfBtAHdfYmaPA0uBSuAKd9+dqn0FsIhESiZvRXb3i2opGlZL/TuAO9JtXwEsIpESokdBKIBFJFrCdCuyAlhEIiVE+asAFpFosaTLcZsnBbCIRIrmgEVEAqIHsouIBCST64AbmwJYRCIlRPmrABaRaNEyNBGRgIQofxXAIhIt2SFKYAWwiESKpiBERAISolVoCmARiRaNgEVEAhKi/FUAi0i0aAQsIhKQ7BBNAiuARSRSwhO/CmARiZgwPQtCn4osIpGSyU9FNrP/MbMlZrbYzB41szwz62RmM81sefxrx4b2VQEsIpFiZmlvdbRTBFwNHOvuhwPZwIXAeGCWu/cFZsXfN4gCWEQiJZMjYGLTtPlmlgO0AUqBkcCkePkkYFRD+6oAFpFIyc6ytDczG2dm8xO2cXvacfcS4LfAx8BaYLO7zwC6uPvaeJ21QGFD+6qLcCISKfVZB+zuE4AJtbTTkdhotxewCfinmV2SgS5WUwBLILYvej3oLkizdNE+t5DBH+u/Bqxy9/UAZvYUcBKwzsy6uvtaM+sKlDX0BJqCEJFIydRFOGJTDyeYWRuLVR4GLAOmAqPjdUYDUxraV42ARSRSMnUjnLvPNbMngLeBSmABsemKdsDjZjaWWEh/u6HnUACLSKRk8lZkd78VuLXG7nJio+F9pgAWkUgJ0aMgFMAiEi0huhNZASwi0RKmZ0EogEUkUsK0tEsBLCKREqIBsAJYRKJFD2QXEQlIiPJXASwi0aKLcCIiAQlR/iqARSRaNAUhIhIQC9HHciqARSRSckK0EFgBLCKRUp8HsgdNASwikaI5YBGRgIRoAKwAFpFo0TpgEZGAZOsinIhIMLK0DE1EJBghmoEI1aMzRUTqlGXpb3Uxsw5m9oSZvWdmy8zsRDPrZGYzzWx5/GvHBve1oQeKiDRHWWZpb2m4B3je3fsDRxH7WPrxwCx37wvMir9vWF8beqCISHNklv6Wuh3bHzgVeADA3SvcfRMwEpgUrzYJGNXQviqARSRSsrMs7c3MxpnZ/IRtXEJTvYH1wENmtsDM/mZmbYEu7r4WIP61sKF91UU4EYmU+owq3X0CMKGW4hzgaOAqd59rZvewD9MNyWgELCKRYmZpb3UoBordfW78/RPEAnmdmXWNn6srUNbQviqARSRSrB5bKu7+CbDGzPrFdw0DlgJTgdHxfaOBKQ3tq6YgRCRSMnwr8lXAw2aWC3wIXEps4Pq4mY0FPga+3dDGFcAiEimZjF93fwc4NknRsEy0rwAWkUjJCtHzKBXAIhIpYbqwpQAWkUjRJ2KIiAQkPPGrABaRiNEIWEQkINkKYBGRYIQnfhXAIhIxIRoAK4BFJFr0kUQiIgHRCFhEJCCmEbCISDC0CkKqbdu2lckTH+LFmTMoKS4mOzuLHj16ctaIs7n44ktolZsbdBelHvLzWnHKMX0ZPKA7g/t3Z/DAgzm4aycAfnnfc9zx1+dqPfaWH4zgJz8cUec5Djvv53y4ZsNe+045pi8z/nZN2v38xV/+xa8mTE+7fpSEKH8VwI2ptLSEsWO+S2lJCQB5+flUVFSwZMlilixZzHPPTuP+Byayf/v2AfdU0nXsYT2Zcu/l+9RGxa5KPtu8vdbyysqqL+3bVVnJJxs+T9lu2/xc9mubB8BbSz/apz6GmQJY2L17N1df8UNKS0ooKCjgl3f+hhNOPImqqipmvPA8t9/6E95btpSbbryeP913f9DdlXr4bPM23nlvDe8sW8M77xXz6+u+QdeC9L+Jznl3FWd9/556nXPOu6vodcbNKes88YcfcPZXjqBk3UZmvrGsXu1HieaAhSnPPMXyDz4A4Hd/+CNHDRoMQFZWFsO/PgKvqmL8Ddfx2quvMHfObI4/4cQguytpen3BCopOu3Gvfb+4+ryAevOFrgXtOWvoQAAmT51DVZUH3KPghOhplKF6cluoTJvyDADHDTm+OnwTDR9xNkXduu1VV5q/5hpsl5x7PDk52VRVVTHpmTlBdydQWWZpb0FTADeCHTt28M6CtwE4+ZRTk9YxM4YOPQWA2W+83mR9k2gaPTL2E9RL8z7go9JPA+5NsKwev4KmKYhGsOrDlVRVxS6k9Onbt9Z6e8o2bFjP5k2baN+hQ1N0TwI24JADmf/Pm+ndrTO7q5zSsk289vYKJjz+Ku++X1zv9k49ti+HHFwAwMSn38h0d0Mn01MQZpYNzAdK3P0cM+sE/C/QE1gNXODuGxvStkbAjaCs7ItPqS4s7FJrvcIuX5SVrW/wJ1tLyBR03I/+vQ5k+85dtG6Vw6E9u3DZN4byxiM3cOvl59S7vTGjYqPfDRu3MvWlhZnubug0wgj4GiDxquZ4YJa79wVmxd83iEbAjWD7tm3Vr/Py8mutl1iWeIxE08qPy7j5908z7eVFrC7dQGVlFa1ysjn12L7cdtV5HDPwYMZ/fzibtmznnr//O60227fLZ9SwQQA89tybVOyqbMTfQThkcmrXzLoBZwN3ANfGd48ETou/ngS8DNxY89h0aAQs0kQemz6f30+exYqPy6rX+u6q3M2sOe8x7NK7mb94NRC7YWP/dnlptXnhiOPIz4vdzPOQph+A2OMo097MxpnZ/IRtXI3m/gDcACQuzu7i7msB4l8LG9rXBgewmV2aoqz6N/XA/RMaeorQatO2bfXrnTt31FovsSzxGGl5yisq+dm90wDYr20eXx3SL63jRsenH+YtXMXSlWsbrX9hkm2W9ubuE9z92IStOrDM7BygzN3faqy+7ssUxG3AQ8kK4r+JCQA7K2me63YaUWHhF98Qy8rWcWi//knrla1b98UxBQ3+JioRMffdVdWvexV1rrP+oP7dGDygOwAPPaPRb7XMTUEMBc4zsxFAHrC/mf0DWGdmXd19rZl1BRp8ASflCNjMFtayLQJqv7rUwvXqfQhZWbE/2hXLl9dab09Z584FWgEh9TZ61EkAbN1ezj+fb7RBWuhk6iKcu9/k7t3cvSdwIfBvd78EmAqMjlcbDUxpaF/rmoLoAnwPODfJ1rIXG6aQn5/PoMFHA/D6a68mrePuvPHGawCceNLQJuubNF9DjuxZ/Xp1HWt581q34r++fiwAT8x4i207Khqza6Filv7WQHcBZ5jZcuCM+PsGqSuAnwXauftHNbbVxK78SS3OHTkKgDfnzWXhwne/VD7jhekUr1mzV11puXJb5XDbFecCsRHtS3PfT1l/1LBBdNy/DQATn57d6P0Lk/pchEuXu7/s7ufEX3/q7sPcvW/862cN7WvKAHb3se7+Wi1lFzf0pC3BeSPPp++hh+LuXPfjq5g7J/afJPYwnuncfutPgdidcnoORLh02C+fAzq0rd723NLaJq/VXvvb5n/xqNGTj+nDv+67kgtHHEdRYYfq/Tk5WZw25FBmPfhjhhzZC4A7J0xn89baL94CXHp+bPph6cq1zF24KmXdFqcxEriRaB1wI8nJyeGee//Cf1/6PUpLShg3dgx5+fl4VRXl5eUA9B8wkDt//duAeyr1Neex8fQ46IAv7b92zBlcO+aM6vd/nzqHcbf+A4jNS55+fH9OPz52QXb7jgq27Synfbt8clvF/hvu3l3Fbx+ayd2TXkx5/t7dO3Py0YcAuvMtmebwjId0KYAbUVFRN554eiqTHnqQWS/OjD2QPSeHQ/r0YfiIc/RA9hZkyYpSxt/9FMcf2YvD+hzEAR3a0aFdG7bvrGDZh5/wxoKVPPDk6yxZUVpnW6NHnkhWVhblFbt45F/zmqD34RKe+AVzb9xVYi1xGZrUreNxVwbdBWmGdiy4d5/z8+2PPk87c47usX+gea0RsIhESnN4ylm6FMAiEikhmgJWAItItCiARUQCoikIEZGAaAQsIhKQEOWvAlhEIiZECawAFpFI0RywiEhAMv2hnI1JASwi0aIAFhEJhqYgREQComVoIiIBCVH+KoBFJGJClMAKYBGJlDA9kL2uz4QTEQmVTH0ikZl1N7OXzGyZmS0xs2vi+zuZ2UwzWx7/2rGhfVUAi0i0ZO4z4SqB69x9AHACcIWZDQTGA7PcvS8wK/6+QRTAIhIpVo9fqbj7Wnd/O/56C7AMKAJGApPi1SYBoxraVwWwiESKWX02G2dm8xO2ccnbtJ7AYGAu0MXd10IspIHChvZVF+FEJFLqcw3O3ScAE1K3Z+2AJ4Efu/vnlsGLfBoBi0ikZGoKAsDMWhEL34fd/an47nVm1jVe3hUoa2hfFcAiEin1mYJI3Y4Z8ACwzN3vTiiaCoyOvx4NTGloXzUFISKRksFVwEOB7wKLzOyd+L6bgbuAx81sLPAx8O2GnkABLCKRkqkpWnd/jdrzfFgmzqEAFpGICc+dcApgEYkUPZBdRCQgIXoUhAJYRKJFD2QXEQlKePJXASwi0RKi/FUAi0i0aA5YRCQgmXxWQ2NTAItIpIQnfhXAIhIxIRoAK4BFJFq0DE1EJCAaAYuIBEQBLCISEE1BiIgERCNgEZGAhCh/FcAiEjEhSmAFsIhEiuaARUQCEqYHsutTkUUkWqweW11NmQ03s/fNbIWZjc90VxXAIhIpVo9fKdsxywb+BHwdGAhcZGYDM9lXBbCIRIpZ+lsdhgAr3P1Dd68AHgNGZrKvjT4HnJcTohnxRmZm49x9QtD9aA52LLg36C40G/p3kVn1yRwzGweMS9g1IeHvoghYk1BWDBy/7z38gkbATWtc3VWkBdK/i4C4+wR3PzZhS/xGmCzIPZPnVwCLiCRXDHRPeN8NKM3kCRTAIiLJvQn0NbNeZpYLXAhMzeQJtA64aWmeT5LRv4tmyN0rzexK4AUgG3jQ3Zdk8hzmntEpDRERSZOmIEREAqIAFhEJiAK4iTT2LY0SPmb2oJmVmdnioPsiwVAAN4GmuKVRQmkiMDzoTkhwFMBNo9FvaZTwcfdXgM+C7ocERwHcNJLd0lgUUF9EpJlQADeNRr+lUUTCRwHcNBr9lkYRCR8FcNNo9FsaRSR8FMBNwN0rgT23NC4DHs/0LY0SPmb2KDAb6GdmxWY2Nug+SdPSrcgiIgHRCFhEJCAKYBGRgCiARUQCogAWEQmIAlhEJCAKYBGRgCiARUQC8n8hqzq40lGSkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_mtx = confusion_matrix(y_test, predictions)\n",
    "\n",
    "ax = plt.axes()\n",
    "sn.heatmap(confusion_mtx, annot=True,annot_kws={\"size\": 25}, cmap=\"Blues\", ax = ax, fmt='d')\n",
    "ax.set_title('Test Accuracy', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff4389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c123c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(input_shape, opt, fine_tune=False, chans=19, nb_classes=2, \n",
    "             dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
    "             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "    \n",
    "    if dropoutType == 'SpatialDropout1D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout1D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "    \n",
    "    input1 = input_shape\n",
    "    \n",
    "    pooling_layer1_format = 'channels_first'\n",
    "    pooling_layer2_format = 'channels_last'\n",
    "   \n",
    "\n",
    "    ##################################################################\n",
    "    block1       = Conv1D(F1, (kernLength), padding = 'same',\n",
    "                                  # input_shape = ( chans, samples),\n",
    "                                   use_bias = False)(input1)\n",
    "    block1       = BatchNormalization(axis = -1)(block1)\n",
    "   \n",
    "    block1       = Conv1D(5, (chans), padding='same',\n",
    "                          use_bias = False )(block1)\n",
    "    block1       = BatchNormalization(axis = -1)(block1)\n",
    "    block1       = Activation('relu')(block1)\n",
    "    block1       = AveragePooling1D(pool_size=(4),  name='apl1')(block1)\n",
    "    block1       = dropoutType(dropoutRate)(block1)\n",
    " \n",
    "    block2       = Conv1D(5, ( 16),\n",
    "                                   use_bias = False, padding = 'same' )(block1)\n",
    "    block2       = BatchNormalization(axis = -1)(block2)\n",
    "    block2       = Activation('relu')(block2)\n",
    "    #block2       = AveragePooling1D(pool_size=(3), name='apl2')(block2)\n",
    "    block2       = dropoutType(dropoutRate)(block2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    block2       = Conv1D(5, ( 16),\n",
    "                                   use_bias = False, padding = 'same' )(block2)\n",
    "    block2       = BatchNormalization(axis = -1)(block2)\n",
    "    block2       = Activation('relu')(block2)\n",
    "    block2       = dropoutType(dropoutRate)(block2)\n",
    " \n",
    "        \n",
    "    flatten      = Flatten(name = 'flatten')(block2)\n",
    "    \n",
    "    dense        = Dense(1, name = 'dense',  kernel_constraint = max_norm(norm_rate))(flatten)\n",
    "    \n",
    "    softmax      = Activation('sigmoid', name = 'sigmoid')(dense)\n",
    "    \n",
    "    model = Model(inputs=input1, outputs=softmax)\n",
    "    \n",
    "    model.compile(optimizer=opt, \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "023910bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a9fc923",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer \"conv1d\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=5000>, <tf.Tensor: shape=(), dtype=int32, numpy=19>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfine_tune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36mCNN\u001b[1;34m(input_shape, opt, fine_tune, chans, nb_classes, dropoutRate, kernLength, F1, D, F2, norm_rate, dropoutType)\u001b[0m\n\u001b[0;32m     16\u001b[0m pooling_layer2_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels_last\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m##################################################################\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m block1       \u001b[38;5;241m=\u001b[39m \u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernLength\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;66;43;03m# input_shape = ( chans, samples),\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m                               \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m block1       \u001b[38;5;241m=\u001b[39m BatchNormalization(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)(block1)\n\u001b[0;32m     25\u001b[0m block1       \u001b[38;5;241m=\u001b[39m Conv1D(\u001b[38;5;241m5\u001b[39m, (chans), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     26\u001b[0m                       use_bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m )(block1)\n",
      "File \u001b[1;32mE:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mE:\\Users\\dt\\anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\input_spec.py:200\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInputs to a layer should be tensors. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_spec):\n\u001b[1;32m--> 200\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s),\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    201\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but it received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input tensors. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    202\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInputs received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_index, (x, spec) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(inputs, input_spec)):\n\u001b[0;32m    204\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Layer \"conv1d\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=5000>, <tf.Tensor: shape=(), dtype=int32, numpy=19>]"
     ]
    }
   ],
   "source": [
    "model = CNN(input_shape, opt, chans=19, fine_tune=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelCheckpoint callback - save best weights\n",
    "tl_checkpoint_1 = ModelCheckpoint(filepath='../vgg16/V1/weights/model.weights.best.hdf5',\n",
    "                                  save_best_only=True,\n",
    "                                  verbose=1)\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',\n",
    "                           patience=15,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43609e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525a02d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train.reshape(-1,1),\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    epochs=50, \n",
    "#     callbacks=[tl_checkpoint_1, early_stop],\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('../vgg16/V1/model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd011415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c2c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22719899",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291333df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fda751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a8df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([0 if x < 0.5 else 1 for x in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predictions))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e0fb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[0:15])\n",
    "print(y_test[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba75bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597cc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = confusion_matrix(y_test, predictions)\n",
    "\n",
    "ax = plt.axes()\n",
    "sn.heatmap(confusion_mtx, annot=True,annot_kws={\"size\": 25}, cmap=\"Blues\", ax = ax, fmt='d')\n",
    "ax.set_title('Test Accuracy', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d460081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935267ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6918c746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a688b0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a423b929",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba37730",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].transpose().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca1b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reshape(3595, 1250, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac48dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.transpose()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2770dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a4574",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.swapaxes(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93991de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.swapaxes(1, 2).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
